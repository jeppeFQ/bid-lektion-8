---
title: "Machine Learning og Artificial Intelligence"
subtitle: ""
author: "Jeppe Fjeldgaard Qvist"
date: today
format: 
  revealjs:
    #include-after-body: "resources/timer.html"
    navigation-mode: linear
    slide-number: c
    show-slide-number: print
    embed-resources: true
    self-contained-math: true
    smaller: true
    scrollable: true
    theme: default
    include-in-header: 
      - text: |
          <link href="https://fonts.googleapis.com/css2?family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&display=swap" rel="stylesheet">
          <style>
          .reveal {
            font-family: "Libre Baskerville", serif !important;
          }
          .reveal h1, .reveal h2, .reveal h3, .reveal h4, .reveal h5, .reveal h6 {
            font-family: "Libre Baskerville", serif !important;
          }
          .reveal .slides section {
            overflow: visible !important;
          }
          .reveal ul, .reveal ol {
            margin: 0.5em 0;
            padding-left: 1.5em;
            overflow: visible !important;
          }
          .reveal li {
            margin-bottom: 0.25em;
            overflow: visible !important;
          }
          </style>
---

## Dagens program 

TILF√òJ KAPITEL 12 fra grundbog

## Maskinl√¶ring 

<!---

Machine learning (maskinl√¶ring) er et felt inden for kunstig intelligens, hvor computere l√¶rer at l√∏se opgaver og tr√¶ffe beslutninger baseret p√• data, uden at v√¶re eksplicit programmeret til hver enkelt situation. I stedet for at f√∏lge faste, h√•rdkodede regler, l√¶rer systemet m√∏nstre og sammenh√¶nge fra eksempler.

Den fundamentale id√© bag machine learning er at skabe algoritmer der kan forbedre sig selv gennem erfaring. Forestil dig forskellen mellem at l√¶re et barn at genkende en kat ved at give det en liste af specifikke regler (har fire ben, spidse √∏rer, pels osv.) versus at vise barnet hundredvis af billeder af katte. Machine learning fungerer som den anden tilgang: systemet l√¶rer ved at blive eksponeret for mange eksempler.

Processen best√•r typisk af tre hovedelementer:

1. Data udg√∏r grundlaget - det kan v√¶re billeder, tekst, tal, lydfiler eller enhver anden form for information. Jo mere relevant og varieret data systemet f√•r adgang til, desto bedre kan det l√¶re.

2. Algoritmen er den matematiske metode der bruges til at finde m√∏nstre i dataene. Den justerer gradvist sine interne parametre for at blive bedre til opgaven.

3. Modellen er det endelige resultat - et system der har l√¶rt at udf√∏re en specifik opgave, s√•som at klassificere billeder, forudsige priser eller overs√¶tte sprog.

----->

## Det er allerede en del af vores hverdag 

<!----
Machine learning er blevet allestedsn√¶rv√¶rende i moderne teknologi. N√•r Netflix anbefaler serier du m√•ske kan lide, bruger det collaborative filtering til at finde m√∏nstre i hvad lignende brugere har set. N√•r din smartphone kan l√•se op med ansigtsgenkendelse, benytter den computer vision baseret p√• deep learning. Sprogmodeller som dem der driver moderne overs√¶ttelses- og chatbot-systemer er tr√¶net p√• enorme m√¶ngder tekst for at l√¶re sproglige m√∏nstre og sammenh√¶nge.

Inden for sundhedssektoren bruges machine learning til at diagnosticere sygdomme fra medicinske scanninger, ofte med pr√¶cision der matcher eller overg√•r speciall√¶ger. I finanssektoren hj√¶lper det med at opdage svindel, vurdere kreditrisiko og forudsige markedsbev√¶gelser. Selvk√∏rende biler er m√•ske det mest ambiti√∏se eksempel, hvor multiple machine learning systemer arbejder sammen for at forst√• omgivelserne og tr√¶ffe k√∏rebeslutninger i realtid.

----->

## Typer af ML 

<!-----

Machine learning kan opdeles i flere hovedkategorier baseret p√• hvordan systemet l√¶rer:

* Supervised learning (overv√•get l√¶ring) er den mest almindelige tilgang. Her tr√¶nes modellen p√• data hvor det korrekte svar allerede er kendt. Hvis du for eksempel vil l√¶re en model at genkende spam-emails, giver du den tusindvis af emails der allerede er m√¶rket som enten "spam" eller "ikke spam". Modellen l√¶rer derefter at genkende de karakteristika der adskiller spam fra legitime emails. Denne tilgang bruges til b√•de klassifikation (kategorisering) og regression (forudsigelse af numeriske v√¶rdier).

> Forestil dig, at du skal l√¶re et barn at genkende forskellige dyrearter. Den mest oplagte m√•de ville v√¶re at vise barnet billeder af dyr, hvor du hver gang siger: "Det her er en hund", "Det her er en kat", osv. Efter at have set mange eksempler kan barnet begynde at genkende nye dyr, det ikke har set f√∏r.

::: {style="font-size: 0.8em;"}
:::{.incremental}
* I superviseret l√¶ring giver vi computeren et tr√¶ningsdatas√¶t, hvor hver tekst allerede er blevet m√¶rket eller kategoriseret af mennesker.
* Hvis vi for eksempel vil bygge et system til at klassificere filmanmeldelser som positive eller negative, starter vi med at give computeren tusindvis af anmeldelser, hvor vi p√• forh√•nd har markeret hver enkelt som enten positiv eller negativ. **Computeren l√¶rer s√• at finde de sproglige m√∏nstre, der karakteriserer hver kategori.**
* De mest almindelige superviserede metoder til tekstanalyse omfatter klassifikationsalgoritmer som **Naive Bayes**, Support Vector Machines og neurale netv√¶rk. 
* En vigtig pointe er, at kvaliteten af den superviserede model er dybt afh√¶ngig af kvaliteten og omfanget af de "labeled" data, vi tr√¶ner den med.
:::
:::


* Unsupervised learning (uoverv√•get l√¶ring) handler om at finde skjulte strukturer i data uden forudgavede svar. Algoritmen opdager selv m√∏nstre, grupperinger eller sammenh√¶nge. Dette bruges blandt andet til at segmentere kunder i forskellige grupper baseret p√• deres adf√¶rd, eller til at reducere kompleksiteten i datas√¶t med mange dimensioner.

* Reinforcement learning (forst√¶rkningsl√¶ring) er inspireret af hvordan dyr og mennesker l√¶rer gennem bel√∏nning og straf. En agent (det l√¶rende system) interagerer med et milj√∏ og modtager feedback i form af bel√∏nninger for gode handlinger og straffe for d√•rlige. Over tid l√¶rer agenten hvilke strategier der maksimerer den samlede bel√∏nning. Denne tilgang har haft stor succes inden for spil, robotstyring og autonome systemer.

----->

## Hvordan "l√¶rer" man noget? 

<!-----

Lad os tage et konkret eksempel: forestil dig at du vil l√¶re en model at forudsige boligpriser baseret p√• kvadratmeter, antal v√¶relser og beliggenhed.

Modellen starter med tilf√¶ldige g√¶ttev√¶rdier for hvor meget hver faktor betyder. Den laver derefter forudsigelser for alle boliger i tr√¶ningsdataene og sammenligner sine g√¶t med de faktiske priser. Forskellen mellem g√¶t og virkelighed kaldes "fejlen" eller "tabet".

Gennem en proces kaldet optimering justerer modellen gradvist sine interne v√¶gte for at minimere denne fejl. Dette sker typisk gennem en metode kaldet gradient descent, hvor modellen beregner hvordan sm√• √¶ndringer i v√¶gtene p√•virker fejlen, og derefter bev√¶ger sig i retning af mindre fejl. Denne proces gentages mange gange gennem tr√¶ningsdataene, indtil modellen konvergerer mod en l√∏sning der giver gode forudsigelser.


INDS√ÜT TIMER MED SPG. 
----->


## Natural Language Processing (NLP)

*Computervidenskabelig disciplin, der besk√¶ftiger sig med, hvordan en computer kan forst√• og producere menneskeligt sprog.*

::: {style="font-size: 0.8em;"}
* Behandling og bearbejdning af **‚Äúnaturligt sprog‚Äù** ved hj√¶lp af computerteknologi
* Teknikker der involverer statistiske metoder til at forst√• tekst; *med eller uden lingvistiske indsigter*
* Krydsfelt mellem **datalogi og lingvistik**
* Involverer i stigende grad brug af **maskinl√¶ringsteknologi**
    * Eksempler fra hverdagen: *ChatGPT, Tale-til-tekst applikationer, tekstforslag i beskeder, autokorrektur, overs√¶ttelsestjenester (Google Translate)*
:::

## Analyseform√•l 

* **Skabe overblik** (fx n√∏gleordsanalyse)
* Identific√©r og m√•le **pr√¶definerede koncepter** (hate-speech, politisk ideologi, diskurs)
* Udforske og forst√• **komplekse meningssammenh√¶nge** (hvordan temaer opst√•r og udvikler sig, hvordan befolkningsgrupper, institutioner eller andet itales√¶ttes, koblinger mellem temaer, holdning og mening)
* Identific√©r **sociale akt√∏rer** og deres (formodede) **handlinger** (hvem gjorde hvad til hvem?)
* Computationel analyse af **s√¶tningskonstruktion**




## Naive Bayes klassifikation: *l√¶ring gennem sandsynlighedsteori*

> Forestil jer, at du st√•r med en filmanmeldelse og vil afg√∏re, om den er positiv eller negativ. Naive Bayes sp√∏rger: "Givet de ord, jeg ser i denne anmeldelse, hvad er sandsynligheden for, at den tilh√∏rer hver kategori?"

Dette tager afs√¶t i **Bayes' Theorem**/-s√¶tning:

$$
P(C \mid D) = \frac{P(D \mid C) \times P(C)}{P(D)}
$$

S√¶tningen fort√¶ller os, hvordan vi kan vende en betinget sandsynlighed om. Hvis vi kalder vores kategorier for $C$ ("positiv" eller "negativ") og vores dokument for $D$ (repr√¶senteret ved de ord, det indeholder), s√• siger Bayes' s√¶tning:

::: {style="font-size: 0.8em;"}
1. $P(C \mid D)$ er den **posterior sandsynlighed**: sandsynligheden for, at dokumentet tilh√∏rer kategori C, givet at vi har observeret ordene i D.Det er alts√• hvad vi vil finde ud af. 
2. $P(D \mid C)$ er vores **likelihood**: sandsynligheden for at se netop denne kombination af ord, hvis vi ved, at dokumentet tilh√∏rer kategori $C$. 
3. $P(C)$ er **prior sandsynligheden**: vores forh√•ndsforventning om, hvor sandsynlig kategorien er, f√∏r vi har set dokumentet. $P(D)$ er en normaliseringskonstant, der sikrer, at sandsynlighederne summerer til √©n.
:::

---

$$
P(C \mid D) = \frac{P(D \mid C) \times P(C)}{P(D)}
$$

Den naive antagelse er at vi g√•r ud fra uafh√¶ngighed mellem ord. I virkeligheden er ord i en tekst √•benlyst ikke uafh√¶ngige af hinanden.

Naive Bayes **antager**, at alle ord er betingelsesvist uafh√¶ngige givet kategorien, udtrykt som:

$$
P(D \mid C) = P(w_1, w_2, \ldots, w_n \mid C) = P(w_1 \mid C) \times P(w_2 \mid C) \times \cdots \times P(w_n \mid C)
$$


hvor $w_1, w_2, \ldots, w_n$ er de individuelle ord i dokumentet. **Denne antagelse er objektivt forkert, men den fungerer stadig i praksis, fordi den g√∏r beregningerne h√•ndterbare.**


## Naive Bayes som *Sentimentanalyse*

Forstil jer at vi har tr√¶net en model p√• tusindvis af filmanmeldelser, og vi ser denne korte anmeldelse: `"Fantastisk film. Elsker!"`.

::: {style="font-size: 0.8em;"}
::: {.incremental}
1. Vi har to kategorier: `positiv` ($P$) og `negativ` ($N$).
2. Fra vores tr√¶ningsdata har vi l√¶rt f√∏lgende sandsynligheder. 
    * Prior sandsynlighederne er $P(P) = 0.6$ og $P(N) = 0.4$: fordi $60$ procent af vores tr√¶ningsanmeldelser var positive. 
    * Hvor ofte hvert ord optr√¶der i hver kategori: 
      * $P(\text{fantastisk}|P) = 0.08$ (optr√•dte i 8 procent af positive anmeldelser) og $P(\text{fantastisk}|N) = 0.01$ (kun 1 procent negative anmeldelser). 
      * $P(\text{film}|P) = 0.15$ og $P(\text{film}|N) = 0.12$
      * $P(\text{elsker}|P) = 0.09$ og $P(\text{elsker}|N) = 0.02$
:::
:::

---

::: {style="font-size: 0.8em;"}
::: {.incremental}
3. Nu kan vi beregne den unormaliserede posterior sandsynlighed for positiv kategori:
    * $P(P \mid D) \propto P(P) \times P(\text{fantastisk} \mid P) \times P(\text{film} \mid P) \times P(\text{elsker} \mid P)$
    * $P(P \mid D) \propto 0.6 \times 0.08 \times 0.15 \times 0.09 = 0.0006480$
4. Tilsvarende for negativ kategori:
    * $P(N \mid D) \propto P(N) \times P(\text{fantastisk} \mid N) \times P(\text{film} \mid N) \times P(\text{elsker} \mid N)$
    * $P(N \mid D) \propto 0.4 \times 0.01 \times 0.12 \times 0.02 = 0.0000096$
5. Selv uden at normalisere kan vi se, at den positive sandsynlighed er omkring $67$ gange h√∏jere end den negative. Efter **normalisering** ville $P(P|D)$ v√¶re cirka $0.985$, s√• modellen er meget sikker p√•, at dette er en positiv anmeldelse.
:::
:::

# √òvelse

## Hvilken problemer opst√•r i l√¶ring? 

<!------

Machine learning er ikke en universall√∏sning. Systemerne er kun s√• gode som den data de tr√¶nes p√•. Hvis tr√¶ningsdataene er biased eller ufuldst√¶ndige, vil modellen l√¶re og reproducere disse fejl. En ansigtsgenkendelses-algoritme tr√¶net prim√¶rt p√• billeder af en bestemt demografi kan fejle n√•r den m√∏der andre ansigtstyper.

Mange machine learning modeller, is√¶r deep learning netv√¶rk, fungerer som "black boxes" - det kan v√¶re sv√¶rt at forst√• pr√¶cist hvorfor de tr√¶ffer en bestemt beslutning. Dette skaber udfordringer inden for omr√•der hvor transparens og forklarlighed er kritiske, s√•som medicinske diagnoser eller juridiske afg√∏relser.

Desuden kr√¶ver mange moderne machine learning systemer enorme m√¶ngder data og beregningskraft for at tr√¶ne, hvilket kan v√¶re dyrt og milj√∏m√¶ssigt belastende. Og selvom modeller kan v√¶re utroligt dygtige til specifikke opgaver, mangler de den generelle intelligens og robusthed som mennesker besidder.

Machine learning repr√¶senterer en fundamental forskydning i hvordan vi bygger intelligente systemer - fra h√•ndskrevne regler til datadrevet l√¶ring. Det er et felt i rivende udvikling der forts√¶tter med at transformere industrier og √•bne nye muligheder, samtidig med at det rejser vigtige sp√∏rgsm√•l om etik, bias og ansvar i AI-systemer.

----->

## ML algoritmer 

<!----

LAV LISTE
Disse algoritmer repr√¶senterer fundamentet i machine learning. I praksis kombineres de ofte, ensembles bygges, og hyperparametre tunes omhyggeligt. Valget af algoritme afh√¶nger af dit problem, datam√¶ngde, krav til fortolkelighed, og computational resourcer. Der er ingen "bedste" algoritme - det handler om at forst√• styrker og svagheder og v√¶lge det rigtige v√¶rkt√∏j til jobbet.RetryJ




G√òR F√òLGENDE "VALGFRI" L√ÜSNING VED AT TRYKKE NED

Line√¶r Regression
Line√¶r regression er en af de enkleste og mest fundamentale algoritmer. Den s√∏ger at finde en ret linje (eller et hyperplan i flere dimensioner) der bedst beskriver forholdet mellem input-features og output.
Matematisk udtrykkes dette som: y = w‚ÇÅx‚ÇÅ + w‚ÇÇx‚ÇÇ + ... + w‚Çôx‚Çô + b
Her er x'erne dine input-features (f.eks. kvadratmeter, antal v√¶relser), w'erne er v√¶gte der fort√¶ller hvor meget hver feature betyder, og b er en bias-term (sk√¶ringspunktet med y-aksen).
L√¶ringen foreg√•r ved at justere v√¶gtene s√• den samlede fejl minimeres. Fejlen m√•les typisk med Mean Squared Error (MSE), der beregner gennemsnittet af de kvadrerede forskelle mellem forudsigelser og faktiske v√¶rdier. Kvadreringen sikrer at b√•de positive og negative fejl t√¶ller, og st√∏rre fejl straffes h√•rdere.
Algoritmen bruger gradient descent: den beregner hvordan sm√• √¶ndringer i hver v√¶gt p√•virker fejlen (gradienten), og flytter v√¶gtene i modsat retning af gradienten. Dette gentages iterativt indtil modellen konvergerer. Forestil dig at du er p√• et bjerg i t√•ge og vil ned i dalen - du f√∏ler h√¶ldningen omkring dig og tager sm√• skridt i den retning der g√•r mest nedad.
Fordele: Hurtig, simpel at implementere og fortolke, fungerer godt n√•r sammenh√¶nge er line√¶re.
Ulemper: Kan kun modellere line√¶re forhold, f√∏lsom over for outliers.




Logistisk Regression
Trods navnet bruges logistisk regression til klassifikation, ikke regression. Den forudsiger sandsynligheden for at noget tilh√∏rer en bestemt kategori.
Algoritmen tager den line√¶re kombination af features (som i line√¶r regression), men sender resultatet gennem en sigmoid-funktion der presser output til et interval mellem 0 og 1. Sigmoid-funktionen ser ud som et S og er defineret som: œÉ(z) = 1 / (1 + e‚Åª·∂ª)
Hvis vi skal klassificere emails som spam eller ikke-spam, vil modellen beregne en score og konvertere den til en sandsynlighed. En sandsynlighed over 0.5 klassificeres typisk som "spam", under 0.5 som "ikke spam".
Tr√¶ningen bruger en tabsfunktion kaldet cross-entropy loss, der straffes s√¶rligt h√•rdt n√•r modellen er meget sikker, men tager fejl. Optimering sker igen gennem gradient descent.
For problemer med flere kategorier (multi-class classification) bruges softmax regression, der generaliserer logistisk regression til at h√•ndtere mere end to klasser.





Decision Trees (Beslutningstr√¶er)
Decision trees tr√¶ffer beslutninger gennem en serie af ja/nej sp√∏rgsm√•l, organiseret i en tr√¶struktur. Hver intern node repr√¶senterer et sp√∏rgsm√•l om en feature, hver gren repr√¶senterer et svar, og hvert blad repr√¶senterer en klassifikation eller forudsigelse.
S√•dan bygges tr√¶et:
Algoritmen starter med hele datas√¶ttet ved roden og stiller sp√∏rgsm√•let: "Hvilket split giver mig den reneste opdeling?" Den evaluerer alle mulige m√•der at dele dataene p√• og v√¶lger den der maksimerer "information gain" eller minimerer "Gini impurity".
Gini impurity m√•ler hvor "blandede" klasserne er i en node. En ren node (kun √©n klasse) har Gini = 0, mens en perfekt blandet node har h√∏jere Gini. Formlen er: Gini = 1 - Œ£(p·µ¢¬≤) hvor p·µ¢ er sandsynligheden for klasse i.
Information gain m√•ler reduktionen i entropi (uorden) efter et split. Algoritmen v√¶lger altid det split der giver h√∏jest information gain.
Denne proces gentages rekursivt for hver undergruppe, indtil et stopkriterium er n√•et (f.eks. maksimal dybde, minimum antal eksempler per blad, eller ingen yderligere forbedring).
Fordele: Intuitive, let at visualisere, h√•ndterer b√•de numeriske og kategoriske data, kr√¶ver minimal data preprocessing.
Ulemper: Tendens til overfitting, ustabile (sm√• √¶ndringer i data kan give meget forskellige tr√¶er), d√•rlige til at ekstrapolere.





Random Forests
Random forests adresserer mange af decision trees' svagheder ved at bruge ensemble learning - at kombinere mange modeller til √©n st√¶rkere model.
Algoritmen bygger hundredvis eller tusinder af decision trees, men introducerer to vigtige elementer af tilf√¶ldighed:
Bootstrap Aggregating (Bagging): Hvert tr√¶ tr√¶nes p√• et tilf√¶ldigt udvalg af tr√¶ningsdata, hvor eksempler kan v√¶lges flere gange (sampling with replacement). Dette skaber variation mellem tr√¶erne.
Feature Randomness: Ved hvert split i hvert tr√¶ overvejes kun et tilf√¶ldigt subset af features i stedet for alle features. Dette forhindrer at dominerende features overtager alle tr√¶er.
N√•r modellen skal lave en forudsigelse, "stemmer" alle tr√¶erne. For klassifikation bruges majority vote, for regression bruges gennemsnit.
Denne diversitet blandt tr√¶erne g√∏r modellen robust: selv hvis enkelte tr√¶er laver fejl eller overfitter, vil flertallet af tr√¶er typisk tr√¶ffe bedre beslutninger. Det er princippet om "wisdom of crowds".
Fordele: H√∏jt pr√¶cis, robust over for overfitting, h√•ndterer manglende data godt, kan estimere feature importance.
Ulemper: Mindre tolkbar end enkelte tr√¶er, langsommere til forudsigelse, kr√¶ver mere hukommelse.






Gradient Boosting
Gradient boosting er en anden ensemble-metode, men med en fundamental anderledes strategi end random forests. I stedet for at bygge tr√¶er uafh√¶ngigt, bygges de sekventielt hvor hvert nyt tr√¶ fors√∏ger at korrigere fejlene fra de foreg√•ende tr√¶er.
Processen:

Start med en simpel forudsigelse (ofte bare gennemsnittet)
Beregn residualerne (forskellen mellem forudsigelse og faktiske v√¶rdier)
Tr√¶n et nyt tr√¶ til at forudsige disse residualer
Tilf√∏j dette tr√¶ til modellen med en lav v√¶gt (learning rate)
Gentag 2-4 hundredvis af gange

Hver iteration fokuserer p√• de eksempler hvor modellen stadig performer d√•rligt. Det er som at have en studiegruppe hvor hver person fokuserer p√• at l√∏se de problemer de andre har haft sv√¶rt ved.
Den endelige forudsigelse er summen af alle tr√¶ernes bidrag: F(x) = f‚ÇÄ(x) + Œ±¬∑f‚ÇÅ(x) + Œ±¬∑f‚ÇÇ(x) + ... + Œ±¬∑f‚Çô(x), hvor Œ± er learning rate.
Moderne implementationer som XGBoost, LightGBM og CatBoost har tilf√∏jet sofistikerede optimeringer der g√∏r gradient boosting ekstremt kraftfuld og effektiv.
Fordele: Ofte den mest pr√¶cise algoritme i praksis, fleksibel, h√•ndterer komplekse forhold.
Ulemper: Mere tilb√∏jelig til overfitting end random forests, kr√¶ver omhyggelig hyperparameter tuning, langsommere tr√¶ning.





Support Vector Machines (SVM)
SVM er en elegant algoritme til klassifikation der s√∏ger at finde den optimale beslutningsgr√¶nse mellem klasser. Id√©en er at finde hyperplanet (i 2D en linje, i 3D et plan, osv.) der maksimerer marginen mellem de to n√¶rmeste punkter fra hver klasse.
Kerneid√©en:
Forestil dig to grupper af punkter p√• et papir. Der er mange linjer du kunne tegne for at adskille dem, men SVM v√¶lger den linje der har st√∏rst mulig afstand til de n√¶rmeste punkter fra begge sider. Disse n√¶rmeste punkter kaldes "support vectors" - de er de eneste punkter der faktisk p√•virker placeringen af beslutningsgr√¶nsen.
Matematisk optimeres dette ved at maksimere: 2/||w||, subject til at alle punkter er korrekt klassificeret med en margin. Her er w v√¶gt-vektoren der definerer hyperplanet.
Kernel-tricket:
SVMs sande styrke kommer fra kernel-tricket. Ofte er data ikke line√¶rt separerbart i det originale feature-space. Kernel-tricket transformerer implicit dataene til et h√∏jere-dimensionelt rum hvor line√¶r separation bliver mulig.
T√¶nk p√• cirkler og kryds blandet sammen p√• en linje. Du kan ikke tegne en ret linje for at adskille dem. Men hvis du tilf√∏jer en dimension (h√∏jde) og l√∏fter alle cirkler op, kan du nu sk√¶re dem ad med et plan. Kernel-funktioner g√∏r dette matematisk elegant uden faktisk at beregne de h√∏j-dimensionelle koordinater.
Popul√¶re kernels inkluderer:

Line√¶r: K(x,y) = x¬∑y
Polynomial: K(x,y) = (x¬∑y + c)^d
RBF (Radial Basis Function): K(x,y) = exp(-Œ≥||x-y||¬≤)

Fordele: Effektiv i h√∏jdimensionelle rum, hukommelseseffektiv, kraftfuld med rigtig kernel.
Ulemper: Langsom p√• store datas√¶t, f√∏lsom over for feature scaling, sv√¶r at fortolke.







K-Nearest Neighbors (KNN)
KNN er m√•ske den mest intuitive machine learning algoritme - den klassificerer baseret p√• hvad de n√¶rmeste naboer stemmer.
S√•dan virker det:
N√•r du skal klassificere et nyt punkt, finder algoritmen de K n√¶rmeste tr√¶ningspunkter (typisk m√•lt med euklidisk afstand) og lader dem "stemme". For klassifikation vinder den klasse der er mest repr√¶senteret blandt naboerne. For regression bruges gennemsnittet af naboernes v√¶rdier.
Valget af K er kritisk:

Lille K (f.eks. 1-3): F√∏lsomt over for st√∏j, komplekse beslutningsgr√¶nser, risiko for overfitting
Stor K: Mere robust, glattere gr√¶nser, men kan udviske lokale m√∏nstre

Afstandsm√•ling er ogs√• vigtig. Euklidisk afstand d = ‚àöŒ£(x·µ¢-y·µ¢)¬≤ er standard, men Manhattan distance (sum af absolutte forskelle) eller Minkowski distance kan v√¶re bedre for visse problemer.
Fordele: Ingen tr√¶ningsfase, simpel at forst√•, fungerer godt med uregelm√¶ssige beslutningsgr√¶nser.
Ulemper: Langsom ved forudsigelse p√• store datas√¶t, f√∏lsom over for irrelevante features og feature scaling, memory-intensive.






Naive Bayes
Naive Bayes bygger p√• Bayes' s√¶tning fra sandsynlighedsteori. Navnet "naive" kommer fra antagelsen om at alle features er uafh√¶ngige givet klassen - en antagelse der sj√¶ldent holder i virkeligheden, men algoritmen virker ofte alligevel overraskende godt.
Bayes' s√¶tning:
P(Class|Features) = P(Features|Class) ¬∑ P(Class) / P(Features)
Dette l√¶ses som: Sandsynligheden for en klasse givet features er lig med sandsynligheden for at se disse features i den klasse, gange den generelle sandsynlighed for klassen, divideret med den generelle sandsynlighed for disse features.
I praksis:
For at klassificere et dokument som spam eller ikke-spam beregner algoritmen:

P(spam|ord‚ÇÅ, ord‚ÇÇ, ..., ord‚Çô)
P(ikke-spam|ord‚ÇÅ, ord‚ÇÇ, ..., ord‚Çô)

Med naive-antagelsen bliver dette: P(spam) ¬∑ P(ord‚ÇÅ|spam) ¬∑ P(ord‚ÇÇ|spam) ¬∑ ... ¬∑ P(ord‚Çô|spam)
Disse sandsynligheder estimeres simpelt fra tr√¶ningsdata ved at t√¶lle frekvenser.
Varianter:

Gaussian Naive Bayes: For kontinuerlige features, antager normal-fordeling
Multinomial Naive Bayes: For opt√¶llingsdata, god til tekstklassifikation
Bernoulli Naive Bayes: For bin√¶re features

Fordele: Ekstremt hurtig, effektiv med lidt data, fungerer godt med h√∏jdimensionelle data, god til tekstklassifikation.
Ulemper: Naive uafh√¶ngighedsantagelse holder sj√¶ldent, kan v√¶re d√•rlig til at estimere sandsynligheder hvis tr√¶ningsdata er utilstr√¶kkelig.







K-Means Clustering
K-means er den mest popul√¶re unsupervised learning algoritme til clustering. Den grupperer data i K klynger baseret p√• lighed.
Algoritmen:

Initialisering: V√¶lg K tilf√¶ldige punkter som initiale cluster centers (centroids)
Assignment: Tildel hvert datapunkt til den n√¶rmeste centroid
Update: Beregn nye centroids som midtpunktet af alle punkter i hver cluster
Gentag: Iter√©r skridt 2-3 indtil centroids ikke l√¶ngere flytter sig (konvergens)

Algoritmen minimerer "within-cluster sum of squares" (WCSS): summen af kvadrerede afstande fra hvert punkt til dets cluster center.
Valg af K:
Elbow-metoden ploter WCSS mod antal clusters. N√•r kurven begynder at flade ud ("albuen"), er det ofte et godt valg af K. Silhouette-score er en anden metrik der m√•ler hvor godt clusteret data er.
Fordele: Simpel, hurtig, skalerer godt til store datas√¶t.
Ulemper: Skal v√¶lge K p√• forh√•nd, f√∏lsom over for initialisering, antager sf√¶riske clusters med lignende st√∏rrelse, f√∏lsom over for outliers.








Principal Component Analysis (PCA)
PCA er en dimensionalitetsreduktions-teknik der transformerer data til et nyt koordinatsystem hvor de f√∏rste dimensioner (principal components) fanger mest varians i dataene.
Hvorfor reducere dimensioner?
H√∏jdimensionelle data er sv√¶re at visualisere, tr√¶ge at processere, og lider af "the curse of dimensionality". PCA hj√¶lper ved at finde de retninger i data hvor der er mest variation og projicere data ned p√• disse retninger.
Matematisk:
PCA finder egenvektorer og egenv√¶rdier af kovariansmatricen. Egenv√¶rdierne fort√¶ller hvor meget varians hver principal component forklarer. De f√∏rste f√• components fanger typisk st√∏rstedelen af variansen.
Hvis dine data har 100 features men de 10 f√∏rste principal components fanger 95% af variansen, kan du reducere fra 100 til 10 dimensioner med minimal informationstab.
Fordele: Reducerer st√∏j, accelererer andre algoritmer, g√∏r visualisering mulig.
Ulemper: Principal components er sv√¶re at fortolke, line√¶r metode (finder kun line√¶re sammenh√¶nge), f√∏lsom over for feature scaling.








Neurale Netv√¶rk - Dybere Forklaring
Et neuralt netv√¶rk best√•r af lag af neuroner. Hver neuron modtager input, anvender en v√¶gt til hvert input, summerer dem, tilf√∏jer en bias, og sender resultatet gennem en aktiveringsfunktion.
Matematisk for √©n neuron:
output = activation(Œ£(w·µ¢ ¬∑ x·µ¢) + b)
Aktiveringsfunktioner:
Disse ikke-line√¶re funktioner giver netv√¶rket evnen til at l√¶re komplekse m√∏nstre:

ReLU (Rectified Linear Unit): f(x) = max(0, x) - Enkel, hurtig, mest popul√¶r
Sigmoid: f(x) = 1/(1+e‚ÅªÀ£) - Output mellem 0 og 1, god til output layer i bin√¶r klassifikation
Tanh: f(x) = (eÀ£-e‚ÅªÀ£)/(eÀ£+e‚ÅªÀ£) - Output mellem -1 og 1, centreret omkring 0
Softmax: Brugt i output layer for multi-class, giver sandsynlighedsfordeling

Backpropagation:
Dette er den centrale l√¶ringsalgoritme i neurale netv√¶rk. Den beregner hvordan fejlen ved output skal fordeles tilbage gennem netv√¶rket for at justere hver v√¶gt:

Forward pass: Data sendes gennem netv√¶rket, lag for lag
Beregn fejl: Sammenlign output med faktisk v√¶rdi
Backward pass: Brug k√¶dereglen fra calculus til at beregne gradienten for hver v√¶gt relativt til fejlen
Opdater v√¶gte: Juster v√¶gte i retning der reducerer fejlen

Dette gentages over mange epochs (genneml√∏b af tr√¶ningsdata) med sm√• learning rates for gradvist at forbedre netv√¶rket.
Regularisering:
For at forhindre overfitting bruges teknikker som:

Dropout: Slukker tilf√¶ldigt for nogle neuroner under tr√¶ning
L1/L2 regularization: Tilf√∏jer straf for store v√¶gte til tabsfunktionen
Batch normalization: Normaliserer aktivationer mellem lag
Early stopping: Stop tr√¶ning n√•r validation loss stopper med at falde


----->

## Algorimer? 

<!-----

INDS√ÜT TIMER 

Den Klassiske Algoritme-Definition
I traditionel computervidenskab defineres en algoritme som:
En pr√¶cis, endelig sekvens af veldefinerede instruktioner der:

Tager et input
Udf√∏rer en beregning gennem diskrete skridt
Producerer et output
Terminerer (stopper) efter et endeligt antal skridt
Er reproducerbar - samme input giver samme output

Eksempel: En sorteringsalgoritme tager en usorteret liste, f√∏lger specifikke regler for at sammenligne og bytte elementer, og returnerer en sorteret liste. Processen er fuldst√¶ndig deterministisk og specificeret p√• forh√•nd.


Det der g√∏r machine learning modeller til "algoritmer" er at de fundamentalt er specificerede, reproducerbare, mekaniske procedurer for at transformere input til output gennem en sekvens af veldefinerede operationer.
B√•de l√¶reprocessen og inferensprocessen er fuldt algoritmiske. Det unikke ved ML sammenlignet med traditionelle algoritmer er at l√¶realgoritmen automatisk syntetiserer inferensalgoritmen baseret p√• data, i stedet for at have inferenslogikken h√•ndkodet.
Men p√• et meta-niveau forbliver alt algoritmisk: sekvenser af pr√¶cise instruktioner, eksekverbare af en maskine, analysable matematisk, reproducerbare i praksis. Machine learning er ikke magi - det er ekstremt sofistikeret anvendelse af algoritmisk t√¶nkning til at automatisere opdagelsen af m√∏nstre i data.
Den dybeste indsigt: ML-algoritmer er algoritmer der skriver algoritmer, men hele k√¶den - fra l√¶ring til inferens - er algoritmisk hele vejen ned.



ML's Dobbelte Natur: To Algoritmer i √ân
Her bliver det interessant. N√•r vi taler om en "machine learning algoritme", refererer vi faktisk til to forskellige algoritmiske processer:
1. L√¶realgoritmen (Training Algorithm)
Dette er den proces der justerer modellens parametre baseret p√• data. DET er kernen i hvad vi mener med "algoritmen". For eksempel:

I gradient descent er algoritmen: beregn gradienten af tabsfunktionen, tag et skridt i modsat retning, gentag indtil konvergens
I decision trees er algoritmen: find det bedste split, opdel data rekursivt, stop ved kriterium
I k-means er algoritmen: tildel punkter til n√¶rmeste centroid, genberegn centroids, gentag indtil stabilitet

Disse er fuldt specificerede, mekaniske processer - pr√¶cis hvad en klassisk algoritme er.
2. Inferens-algoritmen (Prediction Algorithm)
Den tr√¶nede model selv udf√∏rer ogs√• en algoritmisk proces n√•r den laver forudsigelser:

Line√¶r regression: multiplic√©r inputs med v√¶gte og add√©r - deterministisk aritmetik
Neural netv√¶rk: feed-forward propagation gennem lag - specificerede matrix-operationer
K-NN: find K n√¶rmeste naboer, stem - veldefineret s√∏ge- og sammenligningsproces




Fra Matematisk Model til Algoritmisk Implementering
Dette er et centralt punkt: Der er en fundamental forskel mellem den matematiske specifikation og den algoritmiske implementering.
Matematisk niveau:
Line√¶r regression er defineret som at finde v√¶gte w der minimerer: min Œ£(y·µ¢ - w·µÄx·µ¢)¬≤
Dette er en matematisk optimeringsopgave - en specifikation af hvad vi √∏nsker at opn√•, ikke hvordan vi g√∏r det.
Algoritmisk niveau:
Gradient descent giver os en konkret fremgangsm√•de:
1. Initialiser v√¶gte tilf√¶ldigt
2. FOR hver iteration:
   a. Beregn forudsigelser for alle datapunkter
   b. Beregn gradient: ‚àÇL/‚àÇw
   c. Opdater v√¶gte: w := w - Œ±¬∑‚àáL
   d. HVIS konvergens: STOP
3. RETURNER v√¶gte
Det algoritmiske best√•r i at transformere den matematiske idealspecifikation til en mekanisk, step-by-step procedure der kan eksekveres af en computer.
Andre metoder som Normal Equation giver en anden algoritmisk l√∏sning p√• samme matematiske problem: w = (X·µÄX)‚Åª¬πX·µÄy - her er algoritmen matrix-inversion og multiplikation.






Hvad G√∏r Processen "Algoritmisk"?
Lad mig identificere de kerneegenskaber der g√∏r ML-procedurer til √¶gte algoritmer:
1. Mekanisk Eksekverbarhed
Hvert trin i processen er pr√¶cist defineret ned til matematiske operationer der kan udf√∏res mekanisk. Der er ingen "brug din intuition" eller "g√∏r det der f√∏les rigtigt" - ****alt er reduceret til beregninger****.
N√•r gradient descent siger "beregn gradienten", mener den: tag den partielle afledte af tabsfunktionen med hensyn til hver parameter ved hj√¶lp af calculus regler. Det er fuldst√¶ndig specificeret.
2. Reproducerbarhed
Givet samme starttilstand, data, og hyperparametre, vil algoritmen producere identiske resultater (eller i tilf√¶lde med stochastiske elementer: samme statistiske fordeling af resultater med samme random seed).
Dette adskiller ML-algoritmer fra menneskelig l√¶ring. Hvis to mennesker l√¶rer fra samme data, vil deres indre repr√¶sentationer v√¶re forskellige. To identiske neurale netv√¶rk med samme initialisering og data vil l√¶re pr√¶cis det samme.
3. Endelige Operationer
Selvom nogle algoritmer teoretisk kunne k√∏re i evighed, har de praktiske stopbetingelser:

Maksimalt antal iterationer
Konvergens-threshold (n√•r forbedring < Œµ)
Validation performance stabiliserer sig
Timeout

Decision tree algoritmen stopper n√•r den n√•r max_depth eller min_samples_split. Dette sikrer terminering.
4. Decomponerbarhed
Algoritmen kan brydes ned i atomiske operationer: addition, multiplikation, sammenligning, datastruktur-manipulation. Ingen "magiske" skridt.
Backpropagation virker mystisk, men er bare gentagen anvendelse af k√¶dereglen - en mekanisk calculus-operation.
5. Implementeringsuafh√¶ngighed
En algoritme er abstrakt - uafh√¶ngig af dens konkrete implementering. Gradient descent kan implementeres i Python, C++, eller JavaScript, men algoritmen forbliver den samme. Selve proceduren - sekvensen af logiske skridt - er det algoritmiske indhold.


------>

## Det epistemologisk interessante ved ML algoritmer 

<!-----

Her bliver det filosofisk interessant. Traditionelle algoritmer implementerer l√∏sninger vi allerede kender. Sortering l√∏ser et problem vi kan specificere fuldst√¶ndigt.
ML-algoritmer finder l√∏sninger til problemer vi ikke kan specificere eksplicit. Vi kan ikke skrive ned pr√¶cise regler for at genkende en kat, men vi kan skrive en algoritme der l√¶rer disse regler fra data.

Algoritmen er alts√• en metode til at automatisk generere en anden algoritme (modellen).
Dette er meta-algoritmisk: en algoritme der producerer algoritmer. L√¶reprocessen er algoritmisk specificeret, men den resulterende model - selvom den ogs√• er algoritmisk - er ikke forh√•ndsspecificeret af programm√∏ren.


Optimering som Algoritmisk Fundament
P√• det dybeste niveau kan n√¶sten alle ML-algoritmer ses som optimeringsalgoritmer - algoritmer der s√∏ger efter minimum eller maksimum af en funktion.
Optimeringsteori giver os den algoritmiske infrastruktur:
Generel ML-algoritme struktur:

Definer en tabsfunktion L(Œ∏) der m√•ler hvor d√•rlig modellen er
V√¶lg en optimeringsalgoritme (gradient descent, Newton's method, etc.)
Iterativt juster parametre Œ∏ for at minimere L(Œ∏)
Stop ved konvergens eller anden betingelse

Dette framework g√¶lder for line√¶r regression, neurale netv√¶rk, SVM, logistisk regression - de deler alle denne algoritmiske kerne. Forskellen ligger i:

Formen af tabsfunktionen
Strukturen af parameterspace
Valget af optimizer
Regulariseringstermer

Men den underliggende algoritmiske proces - iterativ forbedring gennem gradientf√∏lgning eller anden search-strategi - er f√¶lles.


Hvad Machine Learning IKKE Er
For at forst√• det algoritmiske i ML, kan det hj√¶lpe at se hvad det ikke er:

ML er ikke:
Tilf√¶ldig trial-and-error uden struktur
Mystisk "emergent intelligence" uden mekanisk basis
Uforklarlige "black boxes" p√• algoritmisk niveau (selvom beslutningslogikken kan v√¶re uklar)
Menneskelig-lignende forst√•else eller intuition

ML er:
Systematisk s√∏gning i parameterspace
Mekanisk pattern-matching gennem matematiske transformationer
Optimering af veldefinerede objektive funktioner
Deterministisk manipulation af numeriske repr√¶sentationer

Den komplette algoritmiske proces for line√¶r regression er:

Data Loading ‚Üí Parse CSV/database til arrays
Preprocessing ‚Üí Feature scaling, handling missing values
Split Data ‚Üí Training/validation/test sets
Initialize ‚Üí Set parametre til startv√¶rdier
Training Loop:

Forward pass (matrix multiplikation)
Loss computation (squared errors)
Backward pass (gradient beregning)
Parameter update (v√¶gt opdatering)
Convergence check


Validation ‚Üí Tjek performance p√• usete data
Hyperparameter Tuning ‚Üí Juster learning rate, regularization
Final Evaluation ‚Üí Test p√• holdout set
Deployment ‚Üí Save v√¶gte, load til produktion

Hver eneste operation - fra at l√¶se bytes fra disk til at opdatere en v√¶gt - er en pr√¶cis, mekanisk, reproducerbar proces. Der er ingen magi, kun algoritmer hele vejen ned.
---->



## Et eksempel p√• algoritmisk implementering af OLS 

<!-----

"FRIVILLIG VED AT TRYKKE NED"

Algoritmisk Implementering
Lad mig tage dig gennem hver detalje af hvordan line√¶r regression faktisk implementeres, fra den f√∏rste linje kode til den endelige model. Jeg vil bruge et konkret, simpelt eksempel hele vejen igennem.
Problemformulering
Vi har data hvor vi kender b√•de input (features) og output (target), og vil finde en line√¶r funktion der bedst beskriver forholdet:
y = w‚ÇÅx‚ÇÅ + w‚ÇÇx‚ÇÇ + ... + w‚Çôx‚Çô + b
eller i matrix-form: y = Xw + b
Vores m√•l er at finde v√¶gtene w og bias b der minimerer fejlen mellem forudsigelser og faktiske v√¶rdier.
Konkret Eksempel: Boligpriser
Lad os sige vi vil forudsige huspriser baseret p√• st√∏rrelse (m¬≤) og antal v√¶relser.
Vores tr√¶ningsdata:
St√∏rrelse (m¬≤) | V√¶relser | Pris (mio. kr)
    50         |    1     |    2.0
    80         |    2     |    3.2
   120         |    3     |    4.5
   150         |    4     |    5.8
   200         |    5     |    7.5
Datarepr√¶sentation i Hukommelsen
S√•dan ser dataene faktisk ud n√•r de er loadet i en computer:
Feature matrix X:
[[  50,  1]
 [  80,  2]
 [ 120,  3]
 [ 150,  4]
 [ 200,  5]]
Target vector y:
[2.0, 3.2, 4.5, 5.8, 7.5]
I computerens hukommelse er dette blot arrays af floating-point tal, typisk gemt i sammenh√¶ngende memory blocks. Hver r√¶kke i X er √©n observation, hver kolonne er √©n feature.
Pre-processing: Feature Scaling
F√∏r vi tr√¶ner, skal vi typisk standardisere features s√• de er p√• samme skala. Dette hj√¶lper algoritmerne med at konvergere hurtigere.
Z-score normalisering:
For hver feature: x_scaled = (x - mean(x)) / std(x)
Beregning for st√∏rrelse:
mean = (50 + 80 + 120 + 150 + 200) / 5 = 120
std = ‚àö[(70¬≤ + 40¬≤ + 0¬≤ + 30¬≤ + 80¬≤) / 5] = ‚àö(11400/5) = 47.75

Skaleret st√∏rrelse:
50  ‚Üí (50-120)/47.75  = -1.466
80  ‚Üí (80-120)/47.75  = -0.838
120 ‚Üí (120-120)/47.75 =  0.000
150 ‚Üí (150-120)/47.75 =  0.628
200 ‚Üí (200-120)/47.75 =  1.676
Beregning for v√¶relser:
mean = 3, std = 1.414

1 ‚Üí (1-3)/1.414 = -1.414
2 ‚Üí (2-3)/1.414 = -0.707
3 ‚Üí (3-3)/1.414 =  0.000
4 ‚Üí (4-3)/1.414 =  0.707
5 ‚Üí (5-3)/1.414 =  1.414
Nu er vores X_scaled klar til tr√¶ning.




Gradient Descent (Iterativ Tilgang)
Nu den iterative metode der er mere skalerbar og bruges mest i praksis.
Konceptet
I stedet for at beregne den optimale l√∏sning direkte, starter vi med tilf√¶ldige v√¶gte og forbedrer dem gradvist.
Tabsfunktion (Mean Squared Error):
L(w) = (1/n) √ó Œ£·µ¢(y·µ¢ - ≈∑·µ¢)¬≤
hvor ≈∑·µ¢ = w‚ÇÅx‚ÇÅ·µ¢ + w‚ÇÇx‚ÇÇ·µ¢ + b
Gradienten fort√¶ller os hvordan L √¶ndrer sig n√•r vi √¶ndrer hver v√¶gt.
Matematisk Afledning af Gradient
For at finde gradienten tager vi den partielle afledte af L med hensyn til hver parameter.
For bias b:
‚àÇL/‚àÇb = ‚àÇ/‚àÇb[(1/n) √ó Œ£(y·µ¢ - (w‚ÇÅx‚ÇÅ·µ¢ + w‚ÇÇx‚ÇÇ·µ¢ + b))¬≤]
Ved k√¶dereglen:
= (1/n) √ó Œ£[2(y·µ¢ - (w‚ÇÅx‚ÇÅ·µ¢ + w‚ÇÇx‚ÇÇ·µ¢ + b)) √ó (-1)]
= (-2/n) √ó Œ£(y·µ¢ - ≈∑·µ¢)
For v√¶gt w‚ÇÅ:
‚àÇL/‚àÇw‚ÇÅ = (1/n) √ó Œ£[2(y·µ¢ - ≈∑·µ¢) √ó (-x‚ÇÅ·µ¢)]
= (-2/n) √ó Œ£(y·µ¢ - ≈∑·µ¢) √ó x‚ÇÅ·µ¢
For v√¶gt w‚ÇÇ:
‚àÇL/‚àÇw‚ÇÇ = (-2/n) √ó Œ£(y·µ¢ - ≈∑·µ¢) √ó x‚ÇÇ·µ¢


Den Algoritmiske Implementering

```{python}
# PSEUDOKODE FOR GRADIENT DESCENT

# 1. INITIALISERING
w1 = random_small_value()      # f.eks. 0.01
w2 = random_small_value()      # f.eks. -0.01
b = 0.0
learning_rate = 0.01
max_iterations = 1000
tolerance = 1e-6

# 2. ITERATIV OPTIMERING
for iteration in range(max_iterations):
    
    # 2a. FORWARD PASS - beregn forudsigelser
    predictions = []
    for i in range(n_samples):
        y_pred = w1 * X[i][0] + w2 * X[i][1] + b
        predictions.append(y_pred)
    
    # 2b. BEREGN FEJL
    errors = []
    for i in range(n_samples):
        error = y[i] - predictions[i]
        errors.append(error)
    
    # 2c. BEREGN GRADIENTER
    gradient_w1 = 0
    gradient_w2 = 0
    gradient_b = 0
    
    for i in range(n_samples):
        gradient_w1 += errors[i] * X[i][0]
        gradient_w2 += errors[i] * X[i][1]
        gradient_b += errors[i]
    
    gradient_w1 = (-2.0 / n_samples) * gradient_w1
    gradient_w2 = (-2.0 / n_samples) * gradient_w2
    gradient_b = (-2.0 / n_samples) * gradient_b
    
    # 2d. OPDATER V√ÜGTE
    w1 = w1 - learning_rate * gradient_w1
    w2 = w2 - learning_rate * gradient_w2
    b = b - learning_rate * gradient_b
    
    # 2e. TJEK KONVERGENS
    gradient_magnitude = sqrt(gradient_w1¬≤ + gradient_w2¬≤ + gradient_b¬≤)
    if gradient_magnitude < tolerance:
        print(f"Konvergeret efter {iteration} iterationer")
        break
    
    # 2f. (OPTIONAL) LOG PROGRESS
    if iteration % 100 == 0:
        loss = mean(errors¬≤)
        print(f"Iteration {iteration}: Loss = {loss}")

# 3. RETURNER TR√ÜNEDE V√ÜGTE
return w1, w2, b
```

form√•l

Koden implementerer gradient descent for en simpel line√¶r regressionsmodel med to input-funktioner (features) ùë•1 og ùë•2. Modellen er: y^‚Äã=w1‚Äãx1‚Äã+w2‚Äãx2‚Äã+b

Form√•let er at finde parametrene w1‚Äã,w2‚Äã,b som minimerer middelkvadreret fejl (MSE) mellem sande m√•l y og forudsigelser ùë¶^, ved iterativt at opdatere parametrene imod den negative gradient af tabet.

1. Initialisering
```{python}
w1 = random_small_value()      # f.eks. 0.01
w2 = random_small_value()      # f.eks. -0.01
b = 0.0
learning_rate = 0.01
max_iterations = 1000
tolerance = 1e-6
```

w1, w2, b: startv√¶rdier for parametrene. Sm√• tilf√¶ldige startv√¶rdier hj√¶lper med at bryde symmetri.

learning_rate (Œ±): hvor store skridt vi tager i parameter-rummet hver opdatering.

max_iterations: √∏vre gr√¶nse for antal opdateringer (sikrer termination).

tolerance: stop-kriterium ‚Äî hvis gradientens st√∏rrelse bliver mindre end dette, antages konvergens.

2. Iterativ optimering (hovedl√∏kken)

```{python}
for iteration in range(max_iterations):

```

K√∏rer opdateringscyklusser op til max_iterations. Hver iteration estimerer gradienten og opdaterer parametrene.

2a. Forward pass ‚Äî beregn forudsigelser

```{python}
predictions = []
for i in range(n_samples):
    y_pred = w1 * X[i][0] + w2 * X[i][1] + b
    predictions.append(y_pred)

```

For hver datapunkt ùëñ beregnes y^_i‚Äã=w1‚Äãx_i1‚Äã+w2‚Äãx_i2‚Äã+b

Dette er fuld-batch fremadprop ‚Äî alle samples bruges til at beregne fejl og gradient i hver iteration.

2b. Beregn fejl

```{python}
errors = []
for i in range(n_samples):
    error = y[i] - predictions[i]
    errors.append(error)

```

errors[i] = y_i - \hat{y}_i. Bem√¶rk: koden definerer fejl som (sandt - forudsagt). Dette p√•virker fortegnet i gradienten senere.

2c. Beregn gradienter

```{python}
gradient_w1 = 0
gradient_w2 = 0
gradient_b = 0

for i in range(n_samples):
    gradient_w1 += errors[i] * X[i][0]
    gradient_w2 += errors[i] * X[i][1]
    gradient_b += errors[i]

gradient_w1 = (-2.0 / n_samples) * gradient_w1
gradient_w2 = (-2.0 / n_samples) * gradient_w2
gradient_b = (-2.0 / n_samples) * gradient_b

```

F√∏rst summeres errors[i] * x_{ij} over alle samples. Matematiske mellemskridt:

- For tabet L=1/n ‚àëi (yi ‚àíy^ i )2

- ‚àÇL/‚àÇw1 = ‚àí2/n ‚àëi (yi ‚àíy^ i )xi1 (Deraf multiplicatoren -2/n.)

Koden f√∏lger denne formel; bem√¶rk at tegn og faktor (-2/n) matches error = y - y_pred.

gradient_b = ‚àí2/n ‚àëi (yi ‚àíy^ i )


2d. Opdater v√¶gte (gradient descent step)

```{python}
w1 = w1 - learning_rate * gradient_w1
w2 = w2 - learning_rate * gradient_w2
b = b - learning_rate * gradient_b

```

Parametrene flyttes modsat gradienten: w‚Üêw‚àíŒ±‚àáL 

Hvis gradienten er positiv for en parameter, tr√¶kkes der fra parameteren (reducerer parameterv√¶rdi).

2e. Tjek konvergens

```{python}
gradient_magnitude = sqrt(gradient_w1¬≤ + gradient_w2¬≤ + gradient_b¬≤)
if gradient_magnitude < tolerance:
    print(f"Konvergeret efter {iteration} iterationer")
    break

```

Beregner Euclidisk norm (st√∏rrelse) af gradientvektoren.

Hvis denne er under tolerance, antages tabet at v√¶re fladt nok ‚Äî stop.

2f. (Optional) Log progress
```{python}
if iteration % 100 == 0:
    loss = mean(errors¬≤)
    print(f"Iteration {iteration}: Loss = {loss}")

```

Periodisk udskrift af tab (her MSE) for at f√∏lge tr√¶ningsforl√∏bet.


3. Returner tr√¶nede v√¶gte

```{python}
return w1, w2, b

```

Efter konvergens eller max-iterationer returneres de fundne parametre.

Teknisk noter og antagelser
Tabfunktion: implicit bruges MSE: L=n1 ‚àë(yi ‚àíy^ i )2
Batch-type: dette er batch gradient descent ‚Äî hele datas√¶ttet bruges hver iteration. Ikke stokastisk (SGD) og ikke mini-batch.
Tegns√¶tning i fejl: koden bruger error = y - y_pred. Derfor st√•r der et ekstra negativt tegn i gradientberegningen (dera -2/n)
Kompleksitet: per iteration O(n) (her n = n_samples). Total tid O(n‚ãÖiterations).
Numerisk stabilitet: uden feature-skalering kan gradienterne v√¶re meget store eller sm√• ‚Üí l√¶ringsrate skal tilpasses. Anbefaling: normaliser features (z-score eller min-max).
Valg af learning_rate: for stor ‚Üí divergens; for lille ‚Üí langsom konvergens.

----->

## Billedegenkendelse 

<!----

Hvorfor Er Billedgenkendelse Sv√¶rt?
Forestil dig at skulle programmere en computer til at genkende billeder af katte. Med traditionel programmering ville du fors√∏ge at skrive regler:

```{python}
def is_cat(image):
    if has_pointy_ears(image) and has_whiskers(image) and has_fur(image):
        return True
    return False
```

Men hvordan implementerer du has_pointy_ears()? Du ville skulle specificere:

N√∏jagtig form og vinkel p√• √∏rer
Tekstur af pels
Placering af features i forhold til hinanden
Variation i farver, belysning, vinkler, delvis okklusion...

Dette bliver hurtigt umuligt. Der er millioner af variationer - katte i forskellige positioner, med forskelligt lys, delvist skjulte, som killinger eller voksne, forskellige racer. At h√•ndkode alle disse regler er praktisk umuligt.
Machine learning l√∏ser dette ved at l√¶re reglerne fra data i stedet for at f√• dem h√•ndkodet.


1. Data-Drevet L√¶ring
Vi specificerer ikke regler. Vi viser eksempler. Modellen finder selv m√∏nstre:

Hvilke pixel-kombinationer indikerer "kat"?
Hvilke h√∏j-niveau features betyder "Ferrari"?
Hvordan kombineres features til beslutninger?

2. Hierarkisk Feature-L√¶ring
Modellen bygger automatisk en repr√¶sentation fra simpelt til komplekst:
Pixels ‚Üí Kanter ‚Üí Former ‚Üí Dele ‚Üí Objekter ‚Üí Scener
Dette er umuligt at h√•ndkode.

3. Optimering af Objektiv Funktion
Alt reduceres til: "Minimer den gennemsnitlige fejl p√• tr√¶ningsdata"
min Œ£ Loss(f(x_i; Œ∏), y_i)
Hvor f er netv√¶rket, Œ∏ er alle v√¶gte, x_i er billeder, y_i er labels.


4. Generalisering til Usete Data
Magien er at modellen l√¶rer generelle m√∏nstre, ikke bare memorerer tr√¶ningsdata.
En model tr√¶net p√• 60,000 h√•ndskrevne cifre kan genkende din h√•ndskrift - som den aldrig har set f√∏r.



F√∏r ML (traditionel computer vision):

H√•nddesignede features (SIFT, HOG, SURF)
Ingeni√∏rer bruger √•r p√• feature engineering
Brittle systems der fejler ved variation

Med Deep Learning:

Automatisk feature l√¶ring
End-to-end optimering
Robust til variation i data
Overg√•r mennesker p√• mange opgaver

Machine learning til billedgenkendelse er ikke magi. Det er:

Systematisk transformation af pixels gennem lag af matriceoperationer
Hierarkisk abstraktion fra simple til komplekse features
Gradient-baseret optimering af millioner af parametre
Statistisk pattern-matching p√• mega-skala

Men samlet set skaber dette systemer der kan "se" p√• m√•der der var ut√¶nkelige for 20 √•r siden. Fra at genkende cifre til at diagnosticere kr√¶ft, identificere fuglearter, k√∏re biler autonomt, og generere fotorealistiske billeder - alt sammen ved at l√¶re fra data i stedet for at f√∏lge h√•rdkodede regler.





---->

## Datarepr√¶sentation

<!----

Et digitalt billede er en matrix af pixels. Lad os tage et helt simpelt 28√ó28 gr√•tonebillede (som MNIST h√•ndskrevne cifre):



Forestil dig du er en computer der aldrig har set en kat. Alt du ser er tal:
Billede af en kat (forenklet 8√ó8 gr√•tone):
[  10,  15,  20,  25,  25,  20,  15,  10]  ‚Üê M√∏rk baggrund
[  15,  80, 120, 140, 140, 120,  80,  15]  ‚Üê √òverste kant af hoved
[  20, 180, 250, 255, 255, 250, 180,  20]  ‚Üê Kattens pande
[  25, 200,  90, 220, 220,  90, 200,  25]  ‚Üê √òjne (m√∏rke pletter)
[  25, 180, 180, 200, 200, 180, 180,  25]  ‚Üê Snude
[  20, 160, 240, 190, 190, 240, 160,  20]  ‚Üê Mund/n√¶se omr√•de
[  15,  90, 150, 160, 160, 150,  90,  15]  ‚Üê Underkant af ansigt
[  10,  15,  20,  25,  25,  20,  15,  10]  ‚Üê M√∏rk baggrund

Billede af en hund (samme st√∏rrelse):
[  10,  15,  20,  20,  20,  20,  15,  10]
[  15,  70, 100, 110, 110, 100,  70,  15]
[  20, 150, 200, 210, 210, 200, 150,  20]  ‚Üê Mere aflang form
[  25, 170, 180, 200, 200, 180, 170,  25]  ‚Üê Anderledes √∏jen-placering
[  25, 165, 175, 185, 185, 175, 165,  25]  ‚Üê L√¶ngere snude
[  20, 160, 170, 180, 180, 170, 160,  20]
[  15,  80, 140, 160, 160, 140,  80,  15]
[  10,  15,  20,  25,  25,  20,  15,  10]

Opgaven: L√¶r forskellen mellem disse m√∏nstre af tal!

Forward Pass - Iteration 1
Input: Kattebillede (8√ó8)

Backward Pass - L√¶r fra Fejlen
Sand label: Kat ‚Üí [1, 0]
Forudsigelse: [0.38, 0.62]
Fejl: [0.38 - 1.0, 0.62 - 0.0] = [-0.62, 0.62]

```{python}
# Gradient af loss (cross-entropy + softmax):
‚àÇL/‚àÇoutput = predicted - true
           = [0.38 - 1.0, 0.62 - 0.0]
           = [-0.62, 0.62]

Dette fort√¶ller: 
"Kat-neuronen skulle have v√¶ret H√òJERE (-0.62 fejl)"
"Hund-neuronen skulle have v√¶ret LAVERE (+0.62 fejl)"

# Fejl-signal sendes tilbage til convolutional lag:
# "Hvilke features var vigtige for den forkerte beslutning?"

# Hidden neuron 0 bidrog st√¶rkt til Hund-score
# Den var aktiveret af features fra midten af billedet
# Disse features skal justeres!
```

Nyt eksempel, samme process ... 

Efter 10 Tr√¶ningseksempler
Modellen har set:

5 katte-billeder (forskellige vinkler, positioner)
5 hunde-billeder

Efter 100 Tr√¶ningseksempler
Forskellige filtre har specialiseret sig:
Filter 1 - "Rund Form Detektor":
Filter 2 - "Kant Detektor":
Filter 3 - "√òje Detektor":
Filter 4 - "Tekstur Detektor":

Efter 1000 Tr√¶ningseksempler: Ekspert-Niveau



Forst√•else af L√¶reprocessen: Hvad Skete Der?
Fase 1: Prim√¶re Features (Iteration 0-50)
Filtrene l√¶rer basale m√∏nstre:
- Lyse vs m√∏rke omr√•der
- Horisontale/vertikale kanter
- Simple teksturer

Som et barn der l√¶rer "det lyse ting" vs "det m√∏rke ting"


Fase 2: Sammensatte Features (Iteration 50-200)
Filtre begynder at specialisere:
- Filter kombination detekterer "rund + lys + kant" = ansigt
- Dense layer l√¶rer hvilke filter-kombinationer betyder noget

Som et barn der l√¶rer "rund + pels + ansigt-dele = kat"

Fase 3: Kontekst og Disambiguation (Iteration 200+)
Netv√¶rket l√¶rer subtle forskelle:
- Proportioner: Katte har forholdsvis st√∏rre √∏jne
- Tekstur: Kattepels vs hundepels (forskellige frekvenser)
- Form: Katte har mere kompakte ansigter

Som et barn der l√¶rer at skelne mellem ligner-kat og er-kat



Transfer Learning: Genbrugbar Viden
Efter tr√¶ning p√• katte vs hunde kan vi genbruge de l√¶rte features:
# Frys de f√∏rste lag (basale features)
Layer 1-2: FROZEN (kanter, teksturer er universelle!)

# Tilf√∏j nye output neuroner for ny opgave
Layer 4: NEW - [Kat, Hund, Kanin, Hamster]

# Fintune kun sidste lag
# Kun 100-200 eksempler n√∏dvendige i stedet for 1000+!

Fordi: Kaniner har ogs√• pels-tekstur, kanter, former
Det er kun de h√∏j-niveau kombinationer der skal l√¶res




1. Gradvis Abstraktion
Pixels ‚Üí Kanter ‚Üí Former ‚Üí Dele ‚Üí Objekter
2. Automatisk Feature Discovery
Vi specificerede ikke "find runde former"
Netv√¶rket opdagede selv at runde former er vigtige
3. Distribueret Repr√¶sentation
Ingen enkelt neuron "er" kat-detektor
Det er m√∏nsteret af aktivations p√• tv√¶rs af neuroner
4. Datadrevet L√¶ring
Kvalitet af tr√¶ningsdata > Model arkitektur
Diverse eksempler ‚Üí Robust model
Biased data ‚Üí Biased model
5. Iterativ Forbedring
Hver tr√¶ningsiteration: Lille forbedring
1000+ iterationer: Expert-niveau performance
Men aldrig perfekt - statistisk pattern matching

Det er ikke magi. Det er systematisk, iterativ pattern-matching gennem gradient descent p√• en massiv parameterspace. Men resultatet - en model der "forst√•r" hvad en kat er - emerger fra denne simple proces, hvilket er det virkelig smukke ved machine learning.RetryJ

----->

## Neurale Netv√¶rk 

<!----

Et s√¶rligt kraftfuldt omr√•de inden for machine learning er neurale netv√¶rk, der er l√∏st inspireret af hjernens struktur. Disse best√•r af lag af kunstige neuroner der er forbundet med hinanden. Simple neurale netv√¶rk har f√• lag, mens deep learning refererer til netv√¶rk med mange lag (deraf "deep").

Hvert lag i netv√¶rket l√¶rer at genkende forskellige niveauer af abstraktion. I et billedgenkendelses-netv√¶rk kan de f√∏rste lag l√¶re at genkende simple kanter og teksturer, mellemste lag kan kombinere disse til former og m√∏nstre, mens de dybe lag kan genkende komplette objekter som ansigter eller biler. Denne hierarkiske l√¶ringsstruktur g√∏r deep learning s√¶rligt effektiv til komplekse opgaver.







Forward Pass: Data flyder fremad gennem netv√¶rket - fra input til output
Backward Pass: Gradienter flyder bagl√¶ngs gennem netv√¶rket - fra output til input
Forward Pass (Prediction):
Input ‚Üí Layer 1 ‚Üí Layer 2 ‚Üí ... ‚Üí Output ‚Üí Loss
  x       h‚ÇÅ        h‚ÇÇ              ≈∑        L
Forward pass er f√¶rdig. Nu skal vi l√¶re fra denne fejl!


Backward Pass (Learning):
‚àÇL/‚àÇx ‚Üê ‚àÇL/‚àÇW‚ÇÅ ‚Üê ‚àÇL/‚àÇW‚ÇÇ ‚Üê ... ‚Üê ‚àÇL/‚àÇ≈∑ ‚Üê L

Fejlen fra output skal fordeles tilbage til hidden neurons.

Backward Pass: The Magic of Backpropagation
Nu kommer den del der g√∏r at netv√¶rket kan l√¶re. Vi skal beregne gradienten af loss'en med hensyn til HVER ENESTE v√¶gt:
‚àÇL/‚àÇw‚ÇÅ‚ÇÅ, ‚àÇL/‚àÇw‚ÇÇ‚ÇÅ, ‚àÇL/‚àÇw‚ÇÅ‚ÇÇ, ‚àÇL/‚àÇw‚ÇÇ‚ÇÇ, ‚àÇL/‚àÇw‚ÇÉ, ‚àÇL/‚àÇw‚ÇÑ, ‚àÇL/‚àÇb‚ÇÅ, ‚àÇL/‚àÇb‚ÇÇ

V√¶gtene er nu opdateret! Hvis vi k√∏rer forward pass igen med de nye v√¶gte, vil fejlen v√¶re mindre.

FORWARD PASS (v√¶rdier flyder fremad):

x‚ÇÅ=0.05 ‚îÄ‚îÄ0.15‚îÄ‚îÄ‚îê
                ‚îú‚îÄŒ£‚îÄ‚Üí œÉ ‚Üí h‚ÇÅ=0.5933 ‚îÄ‚îÄ0.40‚îÄ‚îÄ‚îê
x‚ÇÇ=0.10 ‚îÄ‚îÄ0.20‚îÄ‚îÄ‚îò +0.35                     ‚îú‚îÄŒ£‚îÄ‚Üí œÉ ‚Üí ≈∑=0.7514
                                            ‚îÇ  +0.60
x‚ÇÅ=0.05 ‚îÄ‚îÄ0.25‚îÄ‚îÄ‚îê                           ‚îÇ
                ‚îú‚îÄŒ£‚îÄ‚Üí œÉ ‚Üí h‚ÇÇ=0.5969 ‚îÄ‚îÄ0.45‚îÄ‚îÄ‚îò
x‚ÇÇ=0.10 ‚îÄ‚îÄ0.30‚îÄ‚îÄ‚îò +0.35

                                        Loss = 0.0110


BACKWARD PASS (gradienter flyder bagl√¶nds):

‚àÇL/‚àÇx‚ÇÅ‚Üê‚îÄ0.0027‚îÄ‚îÄ‚îê
                ‚îú‚ÜêŒ£‚Üê -0.0111 ‚Üê‚îÄ0.0165‚îÄ‚îÄ‚îê
‚àÇL/‚àÇx‚ÇÇ‚Üê‚îÄ0.0027‚îÄ‚îÄ‚îò                      ‚îú‚ÜêŒ£‚Üê -0.0278 ‚Üê ‚àÇL/‚àÇ≈∑=-0.1486
                                       ‚îÇ
‚àÇL/‚àÇx‚ÇÅ‚Üê‚îÄ0.0030‚îÄ‚îÄ‚îê                      ‚îÇ
                ‚îú‚ÜêŒ£‚Üê -0.0125 ‚Üê‚îÄ0.0166‚îÄ‚îÄ‚îò
‚àÇL/‚àÇx‚ÇÇ‚Üê‚îÄ0.0030‚îÄ‚îÄ‚îò

Hver v√¶gt f√•r sin gradient: ‚àÇL/‚àÇw

dW[l]: Hvor meget hver v√¶gt bidrog til fejlen
db[l]: Hvor meget hver bias bidrog til fejlen
da[l-1]: Fejl-signal der sendes tilbage til forrige lag


The Beautiful Dance
Forward og backward pass er en elegant dans af:

Forward: Information transformation
Data ‚Üí Features ‚Üí Abstract representations ‚Üí Predictions

Backward: Error attribution
Loss ‚Üí Output error ‚Üí Hidden errors ‚Üí Input gradients

Update: Iterative improvement
Juster hver v√¶gt baseret p√• dens bidrag til fejl

Dette simple princip - anvendt millioner af gange p√• millioner af parametre - skaber l√¶rende systemer der kan genkende ansigter, forst√• sprog, og spille komplekse spil.

Kernen er:

Forward pass er deterministisk computation
Backward pass er automatisk differentiation via k√¶dereglen
Weight update er gradient descent optimization

Alt sammen mekanisk, algoritmisk, og smukt matematisk - ingen magi, bare calculus og linear algebra anvendt i massiv skala.
----->

## Fra Kaos til Intelligens

<!-----

# Simpelt eksempel:

Tr√¶ningseksempel 1: Kat med lys pande
Pixel v√¶rdi: 245 (lys)
Filter v√¶gt: 0.04
Output: 245 √ó 0.04 = 9.8
‚Üí Bidrog til Kat-klassifikation
‚Üí Gradient: "√òg denne v√¶gt!"
‚Üí Ny v√¶gt: 0.041

Tr√¶ningseksempel 2: Hund med m√∏rkere pande  
Pixel v√¶rdi: 180 (mindre lys)
Filter v√¶gt: 0.041
Output: 180 √ó 0.041 = 7.38
‚Üí Bidrog til Hund-klassifikation
‚Üí Gradient: "Reducer denne v√¶gt!"
‚Üí Ny v√¶gt: 0.040

Tr√¶ningseksempel 3: Kat med lys pande
Pixel v√¶rdi: 250
Filter v√¶gt: 0.040
‚Üí Gradient: "√òg!"
‚Üí Ny v√¶gt: 0.042

# Over tid: V√¶gten stiger n√•r den korrelerer med "kat"
# Resultat: Filter l√¶rer at "lyse omr√•der = kat"



# I Dense Layer:

Neuron 5 udvikling:
Iteration 0:   Tilf√¶ldige v√¶gte
Iteration 100: Begynder at respondre til "rund + lys"
Iteration 200: Specialiseret "kat-ansigt detektor"

Neuron 8 udvikling:
Iteration 0:   Tilf√¶ldige v√¶gte
Iteration 100: Begynder at respondre til "aflang + kant"
Iteration 200: Specialiseret "hunde-kropsdetektor"

# Hvorfor skete dette?

# Neuron 5 havde TILF√ÜLDIGVIS startv√¶rdier der gav
# lidt h√∏jere output for katte tidligt.
# ‚Üí Fik mere Kat-relateret gradient feedback
# ‚Üí Styrkede denne specialisering
# ‚Üí Blev "kat-ekspert"

# Neuron 8 havde startv√¶rdier der tilf√¶ldigvis
# matchede hunde lidt bedre
# ‚Üí Specialiserede sig i hunde

# Dette er "SPONTAN SYMMETRIBRYDNING"
# Fra symmetri (alle neuroner ens) ‚Üí asymmetri (specialisering)


Hvorfor Sker Det? Den Matematiske Essens
1. Gradient Descent Finder Korrelationer
# Simpel matematik:

Loss = (prediction - true_label)¬≤

For at minimere loss:
- V√¶gte der korrelerer med korrekt label ‚Üí √∏ges
- V√¶gte der anti-korrelerer ‚Üí reduceres
- V√¶gte der er ukorrelerede ‚Üí forbliver sm√•

# Eksempel:
V√¶gt W ser ofte pixel=240 n√•r label=kat
‚Üí Gradient skubber W h√∏jere
‚Üí W specialiseres til "detektor for lyse omr√•der p√• katte"

2. Ikke-Linearitet Skaber Kompleksitet
# Uden activation functions:
y = W‚ÇÉ(W‚ÇÇ(W‚ÇÅx))
  = (W‚ÇÉW‚ÇÇW‚ÇÅ)x
  = W_combined √ó x
‚Üí Kun line√¶re transformationer mulige!

# Med activation functions (ReLU):
y = ReLU(W‚ÇÉ(ReLU(W‚ÇÇ(ReLU(W‚ÇÅx)))))
‚Üí Kan l√¶re VILK√ÖRLIGT komplekse funktioner!

# ReLU tilf√∏jer "kn√¶k" i funktionen:
f(x) = max(0, x)

Dette g√∏r at netv√¶rket kan l√¶re:
- IF blob AND edge AND texture THEN cat
- Logiske kombinationer
- Hierarkiske strukturer



HVAD VI PROGRAMMERER:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
- Netv√¶rks-arkitektur (antal lag, neuroner)
- Activation functions (ReLU, sigmoid)
- Loss function (cross-entropy)
- Optimizer (gradient descent)
- Tr√¶ningsdata (billeder + labels)

                    ‚Üì
            [10,000 iterationer]
                    ‚Üì

HVAD DER EMERGERER:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚úó "Roundness detector" ‚Üê VI specificerede IKKE dette
‚úó "Fur texture detector" ‚Üê VI specificerede IKKE dette
‚úó "Whisker detector" ‚Üê VI specificerede IKKE dette
‚úó Hierarkisk struktur ‚Üê VI specificerede IKKE dette
‚úó Specialiserede neuroner ‚Üê VI specificerede IKKE dette

ALT emergerede fra:
- Tilf√¶ldig initialisering
- Systematisk gradient descent
- Statistiske m√∏nstre i data


Konklusion: Fra Kaos til Orden
Start (Iteration 0):
[Tilf√¶ldige tal] ‚Üí [Tilf√¶ldig output] ‚Üí Loss: 0.69
Ingen struktur. Ingen mening. Ren entropil
Midte (Iteration 500):
[Delvist strukturerede tal] ‚Üí [Bedre output] ‚Üí Loss: 0.32
M√∏nstre begynder at forme sig. Vage specialiseringer.
Slut (Iteration 5000):
[H√∏jt strukturerede tal] ‚Üí [Pr√¶cis output] ‚Üí Loss: 0.05
Klar hierarki. Tydelige roller. Emergent intelligens!
N√∏glen:
Ikke √©n v√¶gt "besluttede" at blive roundness-detektor. Ikke √©n neuron "valgte" at specialisere sig i ansigter.
Det EMERGEREDE gradvist gennem:

Millioner af sm√• justeringer
Hver styret af gradient af fejl
Akkumuleret over tusindvis af eksempler
Konvergerende mod strukturer der minimerer loss

Det er ikke magi. Det er emergens fra simple regler gentaget i massiv skala.
Ligesom:

Fugleflokkes m√∏nstre emerger fra simple regler pr. fugl
Bevidstheden emerger fra simple neuroner i hjernen
Liv emerger fra simple kemiske reaktioner

Machine learning er emergent kompleksitet fra matematisk simplicitet.
Og det er derfor det er s√• smukt - og s√• skr√¶mmende kraftfuldt.

------->

## Arkitektur

<!----

"FRIVILLIG SEKTION"

Du er arkitekten der designer bygningen (netv√¶rket).
Gradient descent er byggearbejderne der udfylder detaljerne (v√¶gtene).
Men du bestemmer grundstrukturen!

```{python}
import tensorflow as tf
from tensorflow import keras

# Build model
model = keras.Sequential([
    keras.layers.Conv2D(32, 3, activation='relu', 
                       input_shape=(224, 224, 3)),
    keras.layers.MaxPooling2D(2),
    keras.layers.Conv2D(64, 3, activation='relu'),
    keras.layers.MaxPooling2D(2),
    keras.layers.Conv2D(128, 3, activation='relu'),
    keras.layers.Flatten(),
    keras.layers.Dense(256, activation='relu'),
    keras.layers.Dense(2, activation='softmax')
])

# Load image
image = load_cat_image()  # Shape: (224, 224, 3)
image_batch = np.expand_dims(image, axis=0)  # Shape: (1, 224, 224, 3)

# Create model that outputs intermediate layers
layer_outputs = [layer.output for layer in model.layers[:6]]
activation_model = keras.Model(inputs=model.input, 
                               outputs=layer_outputs)

# Get feature maps
activations = activation_model.predict(image_batch)

# Inspect
print("Layer 1 (Conv2D) output shape:", activations[0].shape)
# (1, 222, 222, 32) ‚Üê batch_size, height, width, channels

print("Layer 2 (MaxPool) output shape:", activations[1].shape)
# (1, 111, 111, 32)

print("Layer 3 (Conv2D) output shape:", activations[2].shape)
# (1, 109, 109, 64)

# Access specific neuron
neuron_value = activations[0][0, 50, 75, 15]
print(f"Neuron at position (50,75) in feature map 15: {neuron_value}")
# 145.73

# Visualize feature map
import matplotlib.pyplot as plt

# Feature map 15 fra layer 1
feature_map_15 = activations[0][0, :, :, 15]
plt.imshow(feature_map_15, cmap='viridis')
plt.title('Feature Map 15 from Layer 1')
plt.colorbar()
plt.show()
```


DENSE LAYER:
100 neuroner
100 inputs per neuron
= 100 √ó 100 = 10,000 v√¶gte ‚úó Mange!

CONV LAYER:
32 filtre
3√ó3√ó1 per filter
= 32 √ó 9 = 288 v√¶gte ‚úì F√•!

Men producerer 26√ó26√ó32 = 21,632 output v√¶rdier!

Dette er EFFEKTIVITETEN i CNN:
F√• v√¶gte, meget output, deling p√• tv√¶rs af positioner


ET CONVOLUTIONAL LAYER har:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

FILTRE (ogs√• kaldet kernels):
- Antal: Du v√¶lger (f.eks. 32, 64, 128)
- Hver filter = √©t s√¶t v√¶gte
- Hver filter scanner hele input
- Hver filter producerer √âN feature map

NEURONER (output positioner):
- Antal: Beregnes automatisk
- = (output_height √ó output_width √ó antal_filtre)
- Hver position i hver feature map = √©n "neuron"

EKSEMPEL:
Conv2D(filters=32, kernel_size=3)
p√• 28√ó28 input

‚Üí 32 filtre
‚Üí Output: 26√ó26√ó32
‚Üí 26 √ó 26 √ó 32 = 21,632 "neuroner"
‚Üí Men kun 32 √ó 9 = 288 v√¶gte!
  (v√¶gtene deles p√• tv√¶rs af positioner)

Hvis du brugte Dense layer direkte p√• billede:
# 8√ó8 pixels billede = 64 pixels
image = [10, 20, 30, 40, ..., 250, 245, 240]  # 64 v√¶rdier

# √ân neuron i dense layer:
neuron_weights = [w‚ÇÅ, w‚ÇÇ, w‚ÇÉ, w‚ÇÑ, ..., w‚ÇÜ‚ÇÉ, w‚ÇÜ‚ÇÑ]  # 64 v√¶gte

# Beregning:
output = pixel‚ÇÅ√ów‚ÇÅ + pixel‚ÇÇ√ów‚ÇÇ + ... + pixel‚ÇÜ‚ÇÑ√ów‚ÇÜ‚ÇÑ + bias

# JA - hver pixel f√•r sin egen v√¶gt!

Visualisering: Dense Neuron Ser HELE Billedet
BILLEDE (8√ó8):                    NEURON:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 10  20  30  40  ‚îÇ ‚îÄ√ów‚ÇÅ,w‚ÇÇ...‚îÄ‚Üí ‚îÇ                  ‚îÇ
‚îÇ 50  60  70  80  ‚îÇ ‚îÄ√ów‚Çâ,w‚ÇÅ‚ÇÄ..‚Üí  ‚îÇ   SUM ALLE       ‚îÇ
‚îÇ 90 100 110 120  ‚îÇ ‚îÄ√ów‚ÇÅ‚Çá...‚îÄ‚îÄ‚Üí  ‚îÇ   ‚Üì              ‚îÇ
‚îÇ130 140 150 160  ‚îÇ ‚îÄ√ów‚ÇÇ‚ÇÖ...‚îÄ‚îÄ‚Üí  ‚îÇ   + bias         ‚îÇ
‚îÇ170 180 190 200  ‚îÇ ‚îÄ√ów‚ÇÉ‚ÇÉ...‚îÄ‚îÄ‚Üí  ‚îÇ   ‚Üì              ‚îÇ
‚îÇ210 220 230 240  ‚îÇ ‚îÄ√ów‚ÇÑ‚ÇÅ...‚îÄ‚îÄ‚Üí  ‚îÇ   ReLU           ‚îÇ
‚îÇ245 250 255 250  ‚îÇ ‚îÄ√ów‚ÇÑ‚Çâ...‚îÄ‚îÄ‚Üí  ‚îÇ   ‚Üì              ‚îÇ
‚îÇ240 235 230 225  ‚îÇ ‚îÄ√ów‚ÇÖ‚Çá...‚îÄ‚îÄ‚Üí  ‚îÇ   output         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Hver pixel har sin egen forbindelse og v√¶gt!

Problem: Dette L√¶rer IKKE Former Godt
# Hvis neuronen skal l√¶re "rund form":

# Pixel 1 (top-venstre hj√∏rne): w‚ÇÅ = 0.01
# Pixel 2: w‚ÇÇ = 0.02
# ...
# Pixel 28 (centrum af rund form): w‚ÇÇ‚Çà = 0.95  ‚Üê H√∏j!
# ...

# PROBLEM:
# Hvis katten flytter sig 2 pixels til h√∏jre,
# s√• er centrum nu ved pixel 30, ikke 28
# Men v√¶gten er stadig h√∏j ved pixel 28!
# ‚Üí Neuronen fejler!

# Dense neurons l√¶rer POSITIONS-SPECIFIKKE m√∏nstre
# Ikke generelle former


Convolutional Layer
# FILTER (3√ó3) = 9 v√¶gte (ikke 64!)
filter = [[w‚ÇÅ, w‚ÇÇ, w‚ÇÉ],
          [w‚ÇÑ, w‚ÇÖ, w‚ÇÜ],
          [w‚Çá, w‚Çà, w‚Çâ]]

# Dette filter anvendes p√• LOKALE OMR√ÖDER:

# Position (0,0) - top-venstre 3√ó3:
patch_1 = [[10, 20, 30],
           [50, 60, 70],
           [90, 100, 110]]

output‚ÇÅ = 10√ów‚ÇÅ + 20√ów‚ÇÇ + 30√ów‚ÇÉ +
          50√ów‚ÇÑ + 60√ów‚ÇÖ + 70√ów‚ÇÜ +
          90√ów‚Çá + 100√ów‚Çà + 110√ów‚Çâ

# Position (0,1) - skift √©n pixel til h√∏jre:
patch_2 = [[20, 30, 40],
           [60, 70, 80],
           [100, 110, 120]]

output‚ÇÇ = 20√ów‚ÇÅ + 30√ów‚ÇÇ + 40√ów‚ÇÉ + ...

# SAMME 9 v√¶gte, forskellige pixels!

BILLEDE (8√ó8):                    FILTER (3√ó3):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ[10  20  30] 40.. ‚îÇ              ‚îÇ w‚ÇÅ w‚ÇÇ w‚ÇÉ‚îÇ
‚îÇ[50  60  70] 80.. ‚îÇ  ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ√ó‚îÄ‚îÄ‚îÄ‚îÇ w‚ÇÑ w‚ÇÖ w‚ÇÜ‚îÇ
‚îÇ[90 100 110]120.. ‚îÇ              ‚îÇ w‚Çá w‚Çà w‚Çâ‚îÇ
‚îÇ130 140 150 160.. ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ170 180 190 200.. ‚îÇ                   ‚îÇ
‚îÇ210 220 230 240.. ‚îÇ                   ‚îÇ
‚îÇ245 250 255 250.. ‚îÇ                   ‚îÇ
‚îÇ240 235 230 225.. ‚îÇ                   ‚ñº
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              Output‚ÇÅ = 85.5

S√• flytter filteret:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 10 [20  30  40]  ‚îÇ
‚îÇ 50 [60  70  80]  ‚îÇ  ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ√ó‚îÄ‚îÄ‚îÄ[Samme filter]
‚îÇ 90[100 110 120]  ‚îÇ
‚îÇ130 140 150 160.. ‚îÇ              Output‚ÇÇ = 95.5
  ...

Kun 9 v√¶gte, men mange output-v√¶rdier!


Forskellen: Position-Specifik vs Position-Invariant
# Dense neuron v√¶gte efter tr√¶ning:
weights = [
    0.01,  # pixel 0 (hj√∏rne)
    0.02,  # pixel 1
    0.03,  # pixel 2
    ...
    0.95,  # pixel 28 (centrum) ‚Üê MEGET H√òJI
    ...
    0.02,  # pixel 63 (hj√∏rne)
]

# Dette betyder:
# "Hvis pixel 28 er lys, er det en kat"

# Problem:
# Hvis katten flytter sig, fejler neuronen!

Conv Filter: L√¶rer "Lys Center Med M√∏rkere Kanter"
# Conv filter v√¶gte efter tr√¶ning:
filter = [[0.12,  0.34,  0.12],
          [0.38,  0.71,  0.38],
          [0.12,  0.34,  0.12]]

# Dette betyder:
# "Hvis centrum er lyst og kanter moderate,
#  aktiver h√∏jt - UANSET HVOR i billedet"

# Dette m√∏nster matcher runde former OVERALT!





Hvordan L√¶res "En Form"?

Trin 1: Simpel Feature (Kant)
F√òR TR√ÜNING - Tilf√¶ldigt filter:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Filter = [[0.02, -0.01,  0.03],
          [0.01,  0.04, -0.02],
          [-0.01,  0.02,  0.01]]

P√• kant i billede:
[[50, 50, 250],      √ó Filter ‚Üí Output: 8.5
 [50, 50, 250],
 [50, 50, 250]]

Ikke s√¶rlig h√∏j output - filteret "ser" ikke kanten


EFTER 500 TR√ÜNINGSITERATIONER:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Filter = [[-0.42,  0.03,  0.45],  ‚Üê L√¶g m√¶rke til m√∏nster!
          [-0.51,  0.05,  0.54],  ‚Üê Negative venstre,
          [-0.42,  0.03,  0.45]]  ‚Üê Positive h√∏jre

P√• kant i billede:
[[50, 50, 250],      √ó Filter ‚Üí Output: 189!
 [50, 50, 250],
 [50, 50, 250]]

= 50√ó(-0.42) + 50√ó0.03 + 250√ó0.45 +
  50√ó(-0.51) + 50√ó0.05 + 250√ó0.54 +
  50√ó(-0.42) + 50√ó0.03 + 250√ó0.45
= -21 + 1.5 + 112.5 + -25.5 + 2.5 + 135 + -21 + 1.5 + 112.5
= 189!

FILTERET HAR L√ÜRT AT GENKENDE KANTER!

Trin 2: Kombineret Feature (Rund Form)
EFTER TR√ÜNING - Dense neuron kombinerer:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Layer 1 outputs (fra forskellige filtre):
kant_top = 120     (Filter_1 fandt kant √∏verst)
kant_right = 115   (Filter_2 fandt kant til h√∏jre)
kant_bottom = 118  (Filter_3 fandt kant nederst)
kant_left = 112    (Filter_4 fandt kant til venstre)
center_bright = 165 (Filter_5 fandt lyst centrum)

# Dense neuron v√¶gte (l√¶rt):
weights = [0.41, 0.42, 0.41, 0.42, 0.52]
          ‚Üë     ‚Üë     ‚Üë     ‚Üë     ‚Üë
       Alle  Alle  Alle  Alle  Centrum
       kanter n√¶sten ens  h√∏jest!

# Output:
roundness = 120√ó0.41 + 115√ó0.42 + 118√ó0.41 + 112√ó0.42 + 165√ó0.52
          = 49.2 + 48.3 + 48.4 + 47.0 + 85.8
          = 278.7

# Hvis v√¶gtene var ens for alle fire kanter:
# ‚Üí Neuronen aktiverer n√•r kanter er symmetriske
# + lyst centrum
# = RUND FORM!

DENNE DENSE NEURON HAR L√ÜRT "RUNDHED"!



Trin 3: Semantisk Koncept (Kat)
EFTER TR√ÜNING - Output neuron kombinerer:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Dense layer outputs:
roundness_neuron = 278     (fra ovenst√•ende)
whisker_neuron = 195       (l√¶rer snurh√•r-features)
ear_neuron = 142           (l√¶rer √∏re-features)
fur_neuron = 168           (l√¶rer pels-features)
dog_body_neuron = 45       (aktiverer p√• hunde)

# Kat-output neuron v√¶gte (l√¶rt):
weights = [0.91,  0.88,  0.76,  0.65,  -0.82]
           ‚Üë      ‚Üë      ‚Üë      ‚Üë       ‚Üë
         Rund  Snurh√•r √òrer   Pels   Anti-hund!

# Output:
cat_score = 278√ó0.91 + 195√ó0.88 + 142√ó0.76 + 168√ó0.65 + 45√ó(-0.82)
          = 252.98 + 171.6 + 107.92 + 109.2 - 36.9
          = 604.8

# Softmax ‚Üí P(Kat) = 0.97

DENNE OUTPUT NEURON HAR L√ÜRT "KAT"!




Et Filter = En Lille Matrix af V√¶gte
# Et 3√ó3 filter er bare 9 tal:
filter = [[0.5, 0.8, 0.5],
          [0.8, 1.0, 0.8],
          [0.5, 0.8, 0.5]]

# Det er ALT det er!
# 9 v√¶gte arrangeret i et grid


FILTER = 3√ó3 GRID AF V√ÜGTE:

    Col 0   Col 1   Col 2
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ  0.5  ‚îÇ  0.8  ‚îÇ  0.5  ‚îÇ  Row 0
  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
  ‚îÇ  0.8  ‚îÇ  1.0  ‚îÇ  0.8  ‚îÇ  Row 1
  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
  ‚îÇ  0.5  ‚îÇ  0.8  ‚îÇ  0.5  ‚îÇ  Row 2
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Dette er et "template" eller "pattern matcher"


Hvordan "Flytter" Filteret Sig? (Convolution Operation)
Step-by-Step: Scanning Billedet

BILLEDE (8√ó8):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 10  20  30  40  50  60  70  80 ‚îÇ
‚îÇ 15  25  35  45  55  65  75  85 ‚îÇ
‚îÇ 20  30  40  50  60  70  80  90 ‚îÇ
‚îÇ 25  35  45  55  65  75  85  95 ‚îÇ
‚îÇ 30  40  50  60  70  80  90 100 ‚îÇ
‚îÇ 35  45  55  65  75  85  95 105 ‚îÇ
‚îÇ 40  50  60  70  80  90 100 110 ‚îÇ
‚îÇ 45  55  65  75  85  95 105 115 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

FILTER (3√ó3):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1  0 -1 ‚îÇ
‚îÇ 1  0 -1 ‚îÇ
‚îÇ 1  0 -1 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò


Position 1: Top-Venstre (0,0)
STEP 1: Placer filter over top-venstre hj√∏rne
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ[10  20  30] 40  50  60  70  80‚îÇ  ‚Üê Filter d√¶kker disse 9 pixels
‚îÇ[15  25  35] 45  55  65  75  85‚îÇ
‚îÇ[20  30  40] 50  60  70  80  90‚îÇ
‚îÇ 25  35  45  55  65  75  85  95‚îÇ
...

FILTER:              INPUT PATCH:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1  0 -1 ‚îÇ    √ó    ‚îÇ10 20 30‚îÇ
‚îÇ 1  0 -1 ‚îÇ         ‚îÇ15 25 35‚îÇ
‚îÇ 1  0 -1 ‚îÇ         ‚îÇ20 30 40‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

BEREGNING (element-wise multiply og sum):
output[0,0] = (10√ó1) + (20√ó0) + (30√ó-1) +
              (15√ó1) + (25√ó0) + (35√ó-1) +
              (20√ó1) + (30√ó0) + (40√ó-1)
            
            = 10 + 0 - 30 +
              15 + 0 - 35 +
              20 + 0 - 40
            
            = -60

OUTPUT FEATURE MAP:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ -60  ?  ? ..‚îÇ
‚îÇ  ?   ?  ? ..‚îÇ
‚îÇ  ?   ?  ? ..‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò


Position 2: Skift √ân Pixel Til H√∏jre (0,1)

STEP 2: "Glid" filteret √©n pixel til h√∏jre
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 10 [20  30  40] 50  60  70  80‚îÇ  ‚Üê Nu d√¶kker vi disse 9 pixels
‚îÇ 15 [25  35  45] 55  65  75  85‚îÇ
‚îÇ 20 [30  40  50] 60  70  80  90‚îÇ
‚îÇ 25  35  45  55  65  75  85  95‚îÇ
...

FILTER:              INPUT PATCH:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1  0 -1 ‚îÇ    √ó    ‚îÇ20 30 40‚îÇ
‚îÇ 1  0 -1 ‚îÇ         ‚îÇ25 35 45‚îÇ
‚îÇ 1  0 -1 ‚îÇ         ‚îÇ30 40 50‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

BEREGNING:
output[0,1] = (20√ó1) + (30√ó0) + (40√ó-1) +
              (25√ó1) + (35√ó0) + (45√ó-1) +
              (30√ó1) + (40√ó0) + (50√ó-1)
            
            = 20 + 0 - 40 +
              25 + 0 - 45 +
              30 + 0 - 50
            
            = -60

OUTPUT FEATURE MAP:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ-60 -60  ? ..‚îÇ
‚îÇ ?   ?   ? ..‚îÇ
‚îÇ ?   ?   ? ..‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Position 3: N√¶ste Position (0,2)
STEP 3: Forts√¶t til h√∏jre
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 10  20 [30  40  50] 60  70  80‚îÇ
‚îÇ 15  25 [35  45  55] 65  75  85‚îÇ
‚îÇ 20  30 [40  50  60] 70  80  90‚îÇ
...

output[0,2] = beregn p√• samme m√•de...
            = -60



INPUT: 224√ó224√ó3 RGB billede
    ‚Üì

LAYER 1: Conv2D(32 filters, 3√ó3)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
- 32 different 3√ó3√ó3 filters
- Each scans entire image
- Output: 222√ó222√ó32
  (32 feature maps, each 222√ó222)

    ‚Üì

LAYER 2: MaxPooling(2√ó2)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
- No filters/weights
- Just takes max of 2√ó2 regions
- Output: 111√ó111√ó32
  (reduced size, same depth)

    ‚Üì

LAYER 3: Conv2D(64 filters, 3√ó3)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
- 64 different 3√ó3√ó32 filters
  (must be 32 deep to match input!)
- Each filter: 3√ó3√ó32 = 288 weights
- Output: 109√ó109√ó64

    ‚Üì

LAYER 4: MaxPooling(2√ó2)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
- Output: 54√ó54√ó64

    ‚Üì

LAYER 5: Conv2D(128 filters, 3√ó3)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
- 128 different 3√ó3√ó64 filters
- Each filter: 3√ó3√ó64 = 576 weights
- Output: 52√ó52√ó128

    ‚Üì

Continue...



START ‚Üí FILTER SCANNING ‚Üí OUTPUT

Frame 1:
INPUT (8√ó8)        FILTER (3√ó3)      OUTPUT (6√ó6)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îê             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ[‚ñì‚ñì‚ñì]   ‚îÇ    √ó    ‚îÇw w‚îÇ    ‚Üí        ‚îÇ[‚úì]     ‚îÇ
‚îÇ[‚ñì‚ñì‚ñì]   ‚îÇ         ‚îÇw w‚îÇ             ‚îÇ        ‚îÇ
‚îÇ[‚ñì‚ñì‚ñì]   ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ        ‚îÇ
‚îÇ        ‚îÇ                           ‚îÇ        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Frame 2:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ [‚ñì‚ñì‚ñì]  ‚îÇ    √ó    [Same filter] ‚Üí  ‚îÇ ‚úì[‚úì]   ‚îÇ
‚îÇ [‚ñì‚ñì‚ñì]  ‚îÇ                           ‚îÇ        ‚îÇ
‚îÇ [‚ñì‚ñì‚ñì]  ‚îÇ                           ‚îÇ        ‚îÇ
‚îÇ        ‚îÇ                           ‚îÇ        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Frame 3:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  [‚ñì‚ñì‚ñì] ‚îÇ    √ó    [Same filter] ‚Üí  ‚îÇ ‚úì ‚úì[‚úì] ‚îÇ
‚îÇ  [‚ñì‚ñì‚ñì] ‚îÇ                           ‚îÇ        ‚îÇ
‚îÇ  [‚ñì‚ñì‚ñì] ‚îÇ                           ‚îÇ        ‚îÇ
‚îÇ        ‚îÇ                           ‚îÇ        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

...continue til hele billedet er scannet...

Final:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        ‚îÇ                           ‚îÇ‚úì‚úì‚úì‚úì‚úì‚úì  ‚îÇ
‚îÇ        ‚îÇ    Alle positioner ‚Üí     ‚îÇ‚úì‚úì‚úì‚úì‚úì‚úì  ‚îÇ
‚îÇ        ‚îÇ    beregnet              ‚îÇ‚úì‚úì‚úì‚úì‚úì‚úì  ‚îÇ
‚îÇ        ‚îÇ                           ‚îÇ‚úì‚úì‚úì‚úì‚úì‚úì  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                     Feature Map!



T√¶nk p√• det som: ****************************************************
√ât filter = √ân type detektor (f.eks. "lodret kant-finder")
Scanning = Lede efter dette m√∏nster OVERALT i billedet
Feature map = Kort over "hvor fandt jeg dette m√∏nster"
Mange filtre = Lede efter mange forskellige m√∏nstre samtidigt!


‚úì Et LAYER har mange FILTRE (f.eks. 32)
‚úì Hvert FILTER producerer √©n FEATURE MAP
‚úì Hver FEATURE MAP indeholder mange "neuroner" (output positioner)
‚úì Eksempel: 32 filtre ‚Üí 32 feature maps √ó 26√ó26 = 21,632 "neuroner"

‚úì Output = 3D tensor (h√∏jde √ó bredde √ó dybde)
‚úì Dybde = antal filtre
‚úì Hver "slice" i dybden = √©n feature map
‚úì Hver v√¶rdi = hvor st√¶rkt filteret responderede der
‚úì H√∏j v√¶rdi = st√¶rk match til filterets m√∏nster

Feature maps eksisterer MELLEM lag
De er outputtet fra √©t lag
Og inputtet til n√¶ste lag

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  Feature    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  Feature    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Layer  ‚îÇ   Maps      ‚îÇ Layer  ‚îÇ   Maps      ‚îÇ Layer  ‚îÇ
‚îÇ   1    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí   ‚îÇ   2    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí   ‚îÇ   3    ‚îÇ
‚îÇ (Conv) ‚îÇ  32√ó222√ó222 ‚îÇ (Pool) ‚îÇ  32√ó111√ó111 ‚îÇ (Conv) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Feature maps er "aktivationer" - output fra lag




En neuron er en beregningsenhed der:

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ NEURON ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                           ‚îÇ
‚îÇ  INPUTS:                                  ‚îÇ
‚îÇ  x‚ÇÅ = 10 ‚îÄ‚îÄ√ów‚ÇÅ=0.5‚îÄ‚îÄ‚îê                     ‚îÇ
‚îÇ                     ‚îÇ                     ‚îÇ
‚îÇ  x‚ÇÇ = 20 ‚îÄ‚îÄ√ów‚ÇÇ=0.8‚îÄ‚îÄ‚îº‚îÄ‚îÄ SUM ‚îÄ‚îÄ‚îê           ‚îÇ
‚îÇ                     ‚îÇ         ‚îÇ           ‚îÇ
‚îÇ  x‚ÇÉ = 15 ‚îÄ‚îÄ√ów‚ÇÉ=0.3‚îÄ‚îÄ‚îò         ‚îÇ           ‚îÇ
‚îÇ                               ‚îÇ           ‚îÇ
‚îÇ  V√ÜGTE: [0.5, 0.8, 0.3]       ‚îÇ           ‚îÇ
‚îÇ                               ‚Üì           ‚îÇ
‚îÇ                             27.5          ‚îÇ
‚îÇ                               ‚îÇ           ‚îÇ
‚îÇ  BIAS: +2.0 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îÇ           ‚îÇ
‚îÇ                               ‚îÇ           ‚îÇ
‚îÇ                               ‚Üì           ‚îÇ
‚îÇ                        ACTIVATION         ‚îÇ
‚îÇ                         (ReLU)            ‚îÇ
‚îÇ                               ‚îÇ           ‚îÇ
‚îÇ                               ‚Üì           ‚îÇ
‚îÇ  OUTPUT: 27.5 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí  ‚îÇ
‚îÇ                                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

NEURONEN = Hele boksen (beregningsenheden)
V√ÜGTENE = De tre tal [0.5, 0.8, 0.3]
BIAS = √ât tal [2.0]

Neuron_i = {
    Inputs: [x‚ÇÅ, x‚ÇÇ, ..., x‚Çô]
    Weights: [w‚ÇÅ, w‚ÇÇ, ..., w‚Çô]  ‚Üê Disse er separate ting!
    Bias: b
    Activation: œÉ
    
    Computation:
    output = œÉ(Œ£(x·µ¢ √ó w·µ¢) + b)
}

NEURON = En "tom beholder" for beregning

F√∏r tr√¶ning:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   NEURON 5          ‚îÇ
‚îÇ                     ‚îÇ
‚îÇ Kan potentielt      ‚îÇ
‚îÇ l√¶re hvad som       ‚îÇ
‚îÇ helst               ‚îÇ
‚îÇ                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Efter tr√¶ning:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   NEURON 5          ‚îÇ
‚îÇ                     ‚îÇ
‚îÇ Har l√¶rt at v√¶re    ‚îÇ
‚îÇ "kat-ansigt         ‚îÇ
‚îÇ detektor"           ‚îÇ
‚îÇ                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Samme beholder (neuron)
Forskelligt indhold (defineret af v√¶gte)



Der er ingen "auto-pilot". Du skal aktivt designe arkitekturen baseret p√• dit problem.

Forskellige Lag-Typer Har Forskellig Matematik
# BILLEDGENKENDELSE (Standard pattern):
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
model = Sequential([
    # Convolutional layers - ALTID f√∏rst til billeder
    Conv2D(32, kernel_size=3),
    ReLU(),
    MaxPooling2D(2),
    
    Conv2D(64, kernel_size=3),
    ReLU(),
    MaxPooling2D(2),
    
    Conv2D(128, kernel_size=3),
    ReLU(),
    
    # Dense layers - til beslutning
    Flatten(),
    Dense(128),
    ReLU(),
    Dropout(0.5),
    
    Dense(10),  # Output: 10 klasser
    Softmax()
])

# Hvorfor denne struktur?
# Conv layers ‚Üí Spatial features (kanter, teksturer, former)
# Dense layers ‚Üí Kombinerer features til klassifikation

1. Hvilken Layer-Type?
# DU beslutter baseret p√• data-type:

IF data = billeder:
    ‚Üí Brug Convolutional layers
    
IF data = sekvenser (tekst, lyd, tidsserie):
    ‚Üí Brug LSTM/GRU eller Transformer layers
    
IF data = tabeller (features uden orden):
    ‚Üí Brug Dense layers
    
IF data = grafer (sociale netv√¶rk):
    ‚Üí Brug Graph Neural Network layers
    
IF data = 3D (medicinske scans):
    ‚Üí Brug 3D Convolutional layers


2. Hvor Mange Lag?
# DU beslutter dybden:

# SHALLOW (1-3 lag):
model = [
    Dense(128),
    Dense(64),
    Dense(10)
]
# Brug til: Simple problemer, sm√• datas√¶t

# MEDIUM (5-10 lag):
model = [
    Conv2D(32, 3),
    Conv2D(64, 3),
    Conv2D(128, 3),
    Dense(256),
    Dense(128),
    Dense(10)
]
# Brug til: Standard problemer (MNIST, CIFAR)

# DEEP (50-200 lag):
model = ResNet50()  # 50 lag!
# Brug til: Komplekse problemer (ImageNet)


3. Hvor Mange Neuroner Per Lag?
# DU beslutter st√∏rrelsen:

# LILLE:
Conv2D(16, 3)    # 16 filtre
Dense(32)        # 32 neuroner

# MEDIUM:
Conv2D(64, 3)    # 64 filtre
Dense(128)       # 128 neuroner

# STOR:
Conv2D(512, 3)   # 512 filtre
Dense(1024)      # 1024 neuroner

# Trade-off:
# Flere neuroner = Mere kapacitet, men langsommere og overfitting-risiko
# F√¶rre neuroner = Hurtigere, men m√•ske ikke nok kapacitet


4. Hvilken Activation Function?
# DU v√¶lger aktivering per lag:

# Hidden layers - Standard i 2025:
ReLU()           # Most common
GELU()           # Modern, bruges i Transformers
Swish()          # Nogle gange bedre end ReLU
LeakyReLU()      # Undg√•r "dying ReLU"

# Output layer - Afh√¶nger af opgave:
Softmax()        # Multi-class klassifikation
Sigmoid()        # Binary klassifikation
Linear()         # Regression (ingen activation)
Tanh()           # Output mellem -1 og 1


Konkret Eksempel: Kat vs Hund Detektor
Du Designer Arkitekturen Selv

# DIN BESLUTNING #1: Problem-type
# ‚Üí Billedklassifikation ‚Üí Brug CNN

# DIN BESLUTNING #2: Input st√∏rrelse
input_shape = (224, 224, 3)  # RGB billede

# DIN BESLUTNING #3: F√∏rste conv layer
# Skal fange basale features
Conv2D(filters=32,           # 32 forskellige feature detectors
       kernel_size=3,        # 3√ó3 vinduer
       activation='relu')    # ReLU activation

# DIN BESLUTNING #4: Pooling
# Reducer st√∏rrelse, bevar vigtige features
MaxPooling2D(pool_size=2)    # 2√ó2 pooling

# DIN BESLUTNING #5: Anden conv layer
# Skal kombinere basale features
Conv2D(filters=64,           # Mere komplekse features
       kernel_size=3,
       activation='relu')

MaxPooling2D(pool_size=2)

# DIN BESLUTNING #6: Tredje conv layer
# H√∏j-niveau features
Conv2D(filters=128,
       kernel_size=3,
       activation='relu')

# DIN BESLUTNING #7: Dense layers
Flatten()                    # Fra 2D til 1D
Dense(128, activation='relu')  # Kombiner features

# DIN BESLUTNING #8: Regularization
Dropout(0.5)                 # Preventer overfitting

# DIN BESLUTNING #9: Output
Dense(2, activation='softmax')  # 2 klasser: Kat, Hund


Hvor Kommer "Standarderne" Fra?
Akademisk Forskning ‚Üí Best Practices
Der Er Ingen "Perfekt Standard"


# Iteration 1: Start simpelt
model_v1 = [
    Conv2D(32, 3),
    MaxPooling2D(),
    Dense(64),
    Dense(2)
]
# Test ‚Üí Accuracy: 75%

# Iteration 2: G√∏r det dybere
model_v2 = [
    Conv2D(32, 3),
    Conv2D(64, 3),  # ‚Üê Tilf√∏jet
    MaxPooling2D(),
    Dense(128),     # ‚Üê St√∏rre
    Dense(2)
]
# Test ‚Üí Accuracy: 82%

# Iteration 3: Tilf√∏j regularization
model_v3 = [
    Conv2D(32, 3),
    Conv2D(64, 3),
    MaxPooling2D(),
    Dropout(0.3),    # ‚Üê Tilf√∏jet
    Dense(128),
    Dropout(0.5),    # ‚Üê Tilf√∏jet
    Dense(2)
]
# Test ‚Üí Accuracy: 87%

# Du pr√∏ver forskellige designs og v√¶lger bedste!





antal v√¶gte = antal inputs til neuronen.

# Efter convolution og pooling:
# Billede reduceret til 7√ó7√ó64 = 3,136 v√¶rdier

# Dense layer neuron:
neuron = Dense(1)

# Denne ENE neuron har:
# ‚Üí 3,136 v√¶gte (√©n for hver input!)
# ‚Üí 1 bias
# ‚Üí Total: 3,137 parametre

weights = [w‚ÇÅ, w‚ÇÇ, w‚ÇÉ, ..., w‚ÇÉ‚ÇÅ‚ÇÉ‚ÇÜ]  # 3,136 tal!

# Beregning:
output = ReLU(Œ£(input_i √ó weight_i) + bias)
       = ReLU(input‚ÇÅ√ów‚ÇÅ + input‚ÇÇ√ów‚ÇÇ + ... + input‚ÇÉ‚ÇÅ‚ÇÉ‚ÇÜ√ów‚ÇÉ‚ÇÅ‚ÇÉ‚ÇÜ + bias)


SIMPELT EKSEMPEL (p√¶dagogisk):
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Input Layer (3)        Dense Layer (1)
[x‚ÇÅ] ‚îÄ‚îÄ‚îÄ w‚ÇÅ ‚îÄ‚îÄ‚îÄ‚îê
               ‚îú‚îÄ‚Üí Neuron: 3 v√¶gte
[x‚ÇÇ] ‚îÄ‚îÄ‚îÄ w‚ÇÇ ‚îÄ‚îÄ‚îÄ‚î§
               ‚îÇ
[x‚ÇÉ] ‚îÄ‚îÄ‚îÄ w‚ÇÉ ‚îÄ‚îÄ‚îÄ‚îò

3 inputs ‚Üí 3 v√¶gte


REALISTISK EKSEMPEL (kat-detektor):
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Input Layer (3,136)        Dense Layer (1)
[x‚ÇÅ] ‚îÄ‚îÄ‚îÄ w‚ÇÅ ‚îÄ‚îÄ‚îÄ‚îê
[x‚ÇÇ] ‚îÄ‚îÄ‚îÄ w‚ÇÇ ‚îÄ‚îÄ‚îÄ‚î§
[x‚ÇÉ] ‚îÄ‚îÄ‚îÄ w‚ÇÉ ‚îÄ‚îÄ‚îÄ‚î§
[x‚ÇÑ] ‚îÄ‚îÄ‚îÄ w‚ÇÑ ‚îÄ‚îÄ‚îÄ‚î§
  ...          ‚îú‚îÄ‚Üí Neuron: 3,136 v√¶gte!
  ...          ‚îÇ
[x‚ÇÉ‚ÇÅ‚ÇÉ‚ÇÑ]‚îÄ w‚ÇÉ‚ÇÅ‚ÇÉ‚ÇÑ‚îÄ‚î§
[x‚ÇÉ‚ÇÅ‚ÇÉ‚ÇÖ]‚îÄ w‚ÇÉ‚ÇÅ‚ÇÉ‚ÇÖ‚îÄ‚î§
[x‚ÇÉ‚ÇÅ‚ÇÉ‚ÇÜ]‚îÄ w‚ÇÉ‚ÇÅ‚ÇÉ‚ÇÜ‚îÄ‚îò

3,136 inputs ‚Üí 3,136 v√¶gte





# Du designer:
architecture = design_network(
    problem_type="image_classification",
    layer_types=[Conv, Conv, Dense, Dense],  ‚Üê Dine valg
    layer_sizes=[32, 64, 128, 2],            ‚Üê Dine valg
    activations=[ReLU, ReLU, ReLU, Softmax]  ‚Üê Dine valg
)

# Resulterende v√¶gte:
# Bestemmes af arkitekturen
# Ofte millioner af v√¶gte
# Men princippet er det samme som med 3 v√¶gte!

# Tr√¶ning optimerer ALLE disse v√¶gte
# For at l√∏se dit problem





----->


## Et eksempel mere 

<!-----

Her er et ekstremt simpelt billede af en kat i gr√•toner (0-255):
Hver celle er √©n pixel's lysstyrke

Rund form: 90
Pels: 85
Snurh√•r: 95


  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
‚îå‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 10‚îÇ 10‚îÇ 15‚îÇ 20‚îÇ 25‚îÇ 30‚îÇ 30‚îÇ 30‚îÇ 30‚îÇ 30‚îÇ 30‚îÇ 25‚îÇ 20‚îÇ 15‚îÇ 10‚îÇ 10‚îÇ 0  ‚Üê M√∏rk baggrund
‚îÇ 10‚îÇ 15‚îÇ 40‚îÇ 80‚îÇ120‚îÇ140‚îÇ150‚îÇ150‚îÇ150‚îÇ150‚îÇ140‚îÇ120‚îÇ 80‚îÇ 40‚îÇ 15‚îÇ 10‚îÇ 1
‚îÇ 15‚îÇ 50‚îÇ120‚îÇ180‚îÇ220‚îÇ240‚îÇ250‚îÇ250‚îÇ250‚îÇ250‚îÇ240‚îÇ220‚îÇ180‚îÇ120‚îÇ 50‚îÇ 15‚îÇ 2  ‚Üê Toppen af hoved
‚îÇ 25‚îÇ100‚îÇ200‚îÇ230‚îÇ245‚îÇ250‚îÇ250‚îÇ250‚îÇ250‚îÇ250‚îÇ250‚îÇ245‚îÇ230‚îÇ200‚îÇ100‚îÇ 25‚îÇ 3  ‚Üê Pande (lys)
‚îÇ 30‚îÇ140‚îÇ220‚îÇ240‚îÇ 60‚îÇ150‚îÇ200‚îÇ220‚îÇ220‚îÇ200‚îÇ150‚îÇ 60‚îÇ240‚îÇ220‚îÇ140‚îÇ 30‚îÇ 4  ‚Üê √òJNE (m√∏rke pletter)
‚îÇ 30‚îÇ150‚îÇ230‚îÇ245‚îÇ 50‚îÇ140‚îÇ200‚îÇ220‚îÇ220‚îÇ200‚îÇ140‚îÇ 50‚îÇ245‚îÇ230‚îÇ150‚îÇ 30‚îÇ 5  
‚îÇ 30‚îÇ145‚îÇ225‚îÇ240‚îÇ180‚îÇ200‚îÇ220‚îÇ230‚îÇ230‚îÇ220‚îÇ200‚îÇ180‚îÇ240‚îÇ225‚îÇ145‚îÇ 30‚îÇ 6  ‚Üê Mellem √∏jne og n√¶se
‚îÇ 28‚îÇ135‚îÇ215‚îÇ230‚îÇ200‚îÇ210‚îÇ 80‚îÇ180‚îÇ180‚îÇ 80‚îÇ210‚îÇ200‚îÇ230‚îÇ215‚îÇ135‚îÇ 28‚îÇ 7  ‚Üê N√ÜSE (m√∏rk i midten)
‚îÇ 25‚îÇ120‚îÇ200‚îÇ220‚îÇ210‚îÇ180‚îÇ190‚îÇ200‚îÇ200‚îÇ190‚îÇ180‚îÇ210‚îÇ220‚îÇ200‚îÇ120‚îÇ 25‚îÇ 8  ‚Üê Under n√¶se
‚îÇ 22‚îÇ100‚îÇ180‚îÇ200‚îÇ200‚îÇ190‚îÇ200‚îÇ210‚îÇ210‚îÇ200‚îÇ190‚îÇ200‚îÇ200‚îÇ180‚îÇ100‚îÇ 22‚îÇ 9  
‚îÇ 20‚îÇ 80‚îÇ150‚îÇ180‚îÇ190‚îÇ200‚îÇ210‚îÇ 30‚îÇ 30‚îÇ210‚îÇ200‚îÇ190‚îÇ180‚îÇ150‚îÇ 80‚îÇ 20‚îÇ 10 ‚Üê MUND (m√∏rk i midten)
‚îÇ 15‚îÇ 60‚îÇ120‚îÇ150‚îÇ170‚îÇ180‚îÇ190‚îÇ150‚îÇ150‚îÇ190‚îÇ180‚îÇ170‚îÇ150‚îÇ120‚îÇ 60‚îÇ 15‚îÇ 11
‚îÇ 12‚îÇ 40‚îÇ 90‚îÇ120‚îÇ140‚îÇ160‚îÇ170‚îÇ170‚îÇ170‚îÇ170‚îÇ160‚îÇ140‚îÇ120‚îÇ 90‚îÇ 40‚îÇ 12‚îÇ 12 ‚Üê Underkant
‚îÇ 10‚îÇ 25‚îÇ 60‚îÇ 90‚îÇ110‚îÇ130‚îÇ140‚îÇ145‚îÇ145‚îÇ140‚îÇ130‚îÇ110‚îÇ 90‚îÇ 60‚îÇ 25‚îÇ 10‚îÇ 13
‚îÇ 10‚îÇ 15‚îÇ 35‚îÇ 60‚îÇ 80‚îÇ100‚îÇ110‚îÇ115‚îÇ115‚îÇ110‚îÇ100‚îÇ 80‚îÇ 60‚îÇ 35‚îÇ 15‚îÇ 10‚îÇ 14
‚îÇ 10‚îÇ 10‚îÇ 20‚îÇ 35‚îÇ 50‚îÇ 65‚îÇ 75‚îÇ 80‚îÇ 80‚îÇ 75‚îÇ 65‚îÇ 50‚îÇ 35‚îÇ 20‚îÇ 10‚îÇ 10‚îÇ 15
‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îò


Rund Form: 90
Find lyse pixels og m√•l deres form:
# Trin 1: Find alle pixels over en threshold (f.eks. 150)
# Dette isolerer kattens hoved fra baggrund

Lyse pixels (>150):
  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
‚îå‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ X ‚îÇ X ‚îÇ   ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ   ‚îÇ X ‚îÇ X ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ   ‚îÇ   ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ   ‚îÇ   ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ   ‚îÇ X ‚îÇ X ‚îÇ   ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ   ‚îÇ   ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ X ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îò

# Trin 2: Find centrum af disse pixels
center_x = gennemsnit af alle X-koordinater ‚âà 7.5
center_y = gennemsnit af alle Y-koordinater ‚âà 5.0

# Trin 3: Beregn afstand fra centrum til hver pixel
# Jo mere ensartet afstanden er, jo mere cirkul√¶r

Afstande fra centrum til kant:
Nord:     5.0 pixels
Syd:      6.0 pixels  
√òst:      6.5 pixels
Vest:     6.5 pixels
Nord-√òst: 6.2 pixels
Nord-Vest: 6.2 pixels
...

# Trin 4: Beregn variation i afstande
mean_distance = 6.0
std_deviation = 0.7  (lav = meget cirkul√¶r)

# Trin 5: Konverter til 0-100 score
roundness = 100 - (std_deviation √ó 15)
          = 100 - (0.7 √ó 15)
          = 100 - 10.5
          = 89.5
          ‚âà 90 ‚úì

Rund Form: 90/100

100 = Perfekt cirkel
90  = Meget rund (vores kat)
70  = Moderat rund (m√•ske en hund)
50  = Aflang (en p√∏lsehund)
30  = Meget aflang (en slange)
10  = N√¶sten ingen rundhed (en pind)


Pels: 85
Pels m√•les ved tekstur-variation:

# Trin 1: Se p√• 3√ó3 regioner og m√•l variation

Tag denne region fra billedet:
[220, 240, 250]
[230, 245, 250]
[225, 240, 245]

# Beregn lokal variation
max_value = 250
min_value = 220
range = 30

# Trin 2: G√∏r dette for mange regioner
Omr√•de ved pande:   range = 30  (moderat variation)
Omr√•de ved kind:    range = 35  (lidt mere variation)
Omr√•de ved √∏je:     range = 200 (h√∏j variation - men det er feature, ikke pels)

# Trin 3: Gennemsnit (ekskluder features som √∏jne)
Gennemsnitlig pels-variation = 32

# Trin 4: Konverter til pels-score
# Moderat variation = pels (hverken glat eller kaotisk)
optimal_range = 30-40
vores_range = 32

pels_score = 100 - abs(32 - 35) √ó 5
           = 100 - 15
           = 85 ‚úì

Pels: 85/100

100 = Meget tydelig pels-tekstur (langh√•ret kat)
85  = God pels-tekstur (vores normalh√•rede kat)
60  = Nogen tekstur (kort pels)
30  = Glat overflade (m√•ske l√¶der, plast)
10  = N√¶sten ingen tekstur (metal, glas)



Snurh√•r: 95
Snurh√•r detekteres ved lange, tynde linjer ud fra ansigtet:

# Trin 1: Find kanten af ansigtet (h√∏j gradient)

Se p√• r√¶kke 7 (ved n√¶sen):
[28‚îÇ135‚îÇ215‚îÇ230‚îÇ200‚îÇ210‚îÇ 80‚îÇ180‚îÇ180‚îÇ 80‚îÇ210‚îÇ200‚îÇ230‚îÇ215‚îÇ135‚îÇ28]
                             ‚Üë                ‚Üë
                          N√¶se              N√¶se

# Fra n√¶se-position (col 6,9) scan udad
Position 6 ‚Üí 5 ‚Üí 4 ‚Üí 3 ‚Üí 2 ‚Üí 1
V√¶rdier: 80 ‚Üí 210 ‚Üí 200 ‚Üí 230 ‚Üí 215 ‚Üí 135

# Gradient: 80‚Üí210 = +130 (meget skarp overgang!)
# Dette indikerer en tynd linje = snurh√•r

# Trin 2: Tjek for lignende m√∏nstre p√• flere r√¶kker
R√¶kke 4: Skarp overgang ved col 4-5: 60‚Üí150 (+90)
R√¶kke 5: Skarp overgang ved col 4-5: 50‚Üí140 (+90)
R√¶kke 8: Moderat overgang ved col 3-4: 200‚Üí210 (+10)

# Trin 3: T√¶l antal st√¶rke overgange
Skarpe overgange (>80): 6 fundet
Moderate overgange (40-80): 3 fundet
Svage overgange (<40): 12 fundet

# Trin 4: Konverter til snurh√•r-score
snurhaar_score = (antal_skarpe √ó 15) + (antal_moderate √ó 5)
               = (6 √ó 15) + (3 √ó 5)
               = 90 + 15
               = 105 (cap at 100)
               ‚âà 95 ‚úì

Snurh√•r: 95/100

100 = Meget tydelige, lange snurh√•r (perfekt kat)
95  = Klare snurh√•r synlige (vores kat)
70  = Nogle tynde linjer synlige
40  = Svage indikationer
10  = Ingen tynde udadg√•ende linjer (ikke kat)





netv√¶rket l√¶rer SELV at beregne disse features!

Trin 1: Raw Pixels ‚Üí Layer 1 (Edge Detection)
Neural network starter med pixels og l√¶rer filtre:

[[-1,  0,  1],
 [-2,  0,  2],
 [-1,  0,  1]]

Dette filter finder vertikale kanter!

Pixels:              Filter:           Output:
[220, 60, 150]      [[-1, 0, 1],
[240, 50, 140]   √ó   [-2, 0, 2],   = st√¶rk respons!
[230, 60, 145]       [-1, 0, 1]]

= 220√ó(-1) + 60√ó0 + 150√ó1 +
  240√ó(-2) + 50√ó0 + 140√ó2 +
  230√ó(-1) + 60√ó0 + 145√ó1
  
= -220 + 0 + 150 +
  -480 + 0 + 280 +
  -230 + 0 + 145
  
= -355  (h√∏j negativ v√¶rdi = kant fra lys til m√∏rk!)




Trin 2: Layer 1 Output ‚Üí Layer 2 (Shape Detection)
Layer 2 kombinerer kant-informationen:
Neuron i Layer 2 der l√¶rer "rundhed":


# Denne neuron f√•r input fra alle Layer 1 filtre
# Den l√¶rer at kigge efter "kanter i en cirkel"

Input fra forskellige dele af billedet:
kant_top:    -120  (kant ved toppen)
kant_right:  -110  (kant til h√∏jre)
kant_bottom: -125  (kant ved bunden)
kant_left:   -115  (kant til venstre)

# V√¶gte (l√¶rt gennem tr√¶ning):
W = [0.4, 0.4, 0.4, 0.4]  # Alle n√¶sten ens = cirkel!

Output = (-120√ó0.4) + (-110√ó0.4) + (-125√ó0.4) + (-115√ó0.4)
       = -48 - 44 - 50 - 46
       = -188
       
ReLU(-188) = 0... men hvis vi inverterer input f√∏rst:
Input_positive = [120, 110, 125, 115]
Output = 120√ó0.4 + 110√ó0.4 + 125√ó0.4 + 115√ó0.4
       = 186

# Normaliseret til 0-100: ‚âà 90 ‚úì



Trin 3: Layer 2 ‚Üí Layer 3 (Texture Detection)
Pels-tekstur neuron:

# Denne neuron l√¶rer at kigge efter variation-m√∏nstre

Input (fra Layer 2's texture-filters):
variation_region_1: 28  (moderat variation)
variation_region_2: 32
variation_region_3: 35
variation_region_4: 29
high_contrast_region: 200  (√∏je - ignorer dette!)

# V√¶gte (l√¶rer at ignorere h√∏j kontrast):
W = [0.6, 0.6, 0.6, 0.6, -0.1]  # Negativ for √∏je!

Output = 28√ó0.6 + 32√ó0.6 + 35√ó0.6 + 29√ó0.6 + 200√ó(-0.1)
       = 16.8 + 19.2 + 21.0 + 17.4 - 20
       = 54.4

# Med bias og activation:
Output = ReLU(54.4 + 30) = 84.4 ‚âà 85 ‚úì


Visuelt: Fra Pixels til Features

BILLEDE (16√ó16 = 256 pixels)
    ‚Üì
    ‚Üì [Convolutional Layer 1 - 8 filtre]
    ‚Üì Hver filter scanner hele billedet
    ‚Üì
FEATURE MAPS (14√ó14√ó8 = 1,568 v√¶rdier)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Filter 1:   ‚îÇ ‚Üí Detekterer horisontale kanter
‚îÇ  [h√∏je      ‚îÇ
‚îÇ   v√¶rdier   ‚îÇ
‚îÇ   ved       ‚îÇ
‚îÇ   toppen]   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Filter 2:   ‚îÇ ‚Üí Detekterer vertikale kanter
‚îÇ  [h√∏je      ‚îÇ
‚îÇ   v√¶rdier   ‚îÇ
‚îÇ   ved       ‚îÇ
‚îÇ   siderne]  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Filter 3:   ‚îÇ ‚Üí Detekterer tekstur
‚îÇ  [moderate  ‚îÇ
‚îÇ   v√¶rdier   ‚îÇ
‚îÇ   over hele ‚îÇ
‚îÇ   ansigtet] ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
    ‚Üì [Pooling - reduc√©r st√∏rrelse]
    ‚Üì
REDUCED MAPS (7√ó7√ó8 = 392 v√¶rdier)
    ‚Üì
    ‚Üì [Convolutional Layer 2 - 16 filtre]
    ‚Üì Kombinerer simple features til komplekse
    ‚Üì
HIGHER FEATURES (5√ó5√ó16 = 400 v√¶rdier)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Filter 9:   ‚îÇ ‚Üí Kombinerer kanter til "rundhed"
‚îÇ  [aktiverer ‚îÇ    Output: h√∏j v√¶rdi ‚âà 90
‚îÇ   ved runde ‚îÇ
‚îÇ   former]   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Filter 11:  ‚îÇ ‚Üí Kombinerer variation til "tekstur"
‚îÇ  [aktiverer ‚îÇ    Output: moderat v√¶rdi ‚âà 85
‚îÇ   ved pels- ‚îÇ
‚îÇ   m√∏nstre]  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Filter 15:  ‚îÇ ‚Üí Finder tynde linjer fra ansigt
‚îÇ  [aktiverer ‚îÇ    Output: h√∏j v√¶rdi ‚âà 95
‚îÇ   ved       ‚îÇ
‚îÇ   snurh√•r]  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
    ‚Üì [Flatten og Dense Layer]
    ‚Üì
ABSTRACT FEATURES (tre neuroner blandt mange)
    [Roundness Neuron: 90]
    [Fur Neuron: 85]
    [Whiskers Neuron: 95]
    ‚Üì
    ‚Üì [Output Layer]
    ‚Üì
PREDICTION
    [Cat: 0.97]
    [Dog: 0.03]







Sammenligning: Kat vs Hund Billede
Kat (vores eksempel):
Rund Form: 90    ‚Üê Runde ansigtstr√¶k
Pels: 85         ‚Üê Moderat pels-tekstur
Snurh√•r: 95      ‚Üê Tydelige snurh√•r

Features i pixels:
- Symmetrisk distribution af lyse v√¶rdier
- J√¶vn variation i tekstur-regioner
- Skarpe lokale kontraster ved ansigt-kant
Hund (lignende st√∏rrelse):
Rund Form: 65    ‚Üê Mere aflang snude
Pels: 88         ‚Üê M√•ske mere tekstur
Snurh√•r: 30      ‚Üê Ingen tydelige snurh√•r

Features i pixels:
[220, 210, 205, 200, 190, 180, 170...]  ‚Üê Gradvis fald (aflang)
Ingen skarpe overgange ved munden
Mere j√¶vn overgang mellem features




N√∏glepointen: Fra Konkret til Abstrakt

NIVEAU 0: R√• Data
[10, 15, 220, 240, 60, 150...]
"Bare en masse tal mellem 0-255"

NIVEAU 1: Lokale Features (Layer 1)
kant_top = -120
kant_right = -115
textur_region = 32
"Simple m√∏nstre i sm√• regioner"

NIVEAU 2: Sammensatte Features (Layer 2)
symmetry_horizontal = 0.85
symmetry_vertical = 0.87
texture_variation = 32
edge_sharpness = 180
"M√∏nstre af m√∏nstre"

NIVEAU 3: Semantiske Features (Layer 3)
roundness = 90
fur_quality = 85
whisker_presence = 95
"Meningsfulde koncepter"

NIVEAU 4: Beslutning (Output)
is_cat = 0.97
is_dog = 0.03
"Endelig klassifikation"




De tal du s√• (90, 85, 95) er IKKE i billedet.
De er emergente egenskaber der opst√•r n√•r neural network'et processerer pixels gennem lag af transformationer.
Billedet indeholder kun:
‚Üí 256 tal mellem 0-255 (pixels)

Neural network'et beregner:
‚Üí Tusindvis af mellemliggende features
‚Üí Hvoraf nogle kan fortolkes som "rundhed", "pels", etc.
‚Üí Men netv√¶rket har aldrig f√•et at vide hvad disse er!
‚Üí Det opdagede selv at disse features er nyttige

Det er derfor det hedder "feature learning"
I stedet for "feature engineering" (hvor VI definerer features)
Tallene 90, 85, 95 er derfor:

Ikke direkte m√•lbare i billedet
Men emergerer naturligt fra netv√¶rkets l√¶ring
Svarer til hvad vi mennesker ville kalde "rund", "pelset", "med snurh√•r"
Men beregnet gennem ren matematik p√• pixels

Det er den smukke bro mellem r√• data og abstrakt forst√•else!






------->
















